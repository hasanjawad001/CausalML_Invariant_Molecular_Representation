{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.5.\n",
      "The scikit-learn version is 1.0.2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/chEMBL26_smiles_v2 were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/chEMBL26_smiles_v2 were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/chEMBL26_smiles_v2 were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 769)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/chEMBL26_smiles_v2 were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 769)\n",
      "(46, 769)\n",
      "(46, 769)\n",
      "(46, 769)\n",
      "(46, 769)\n",
      "(46, 6)\n",
      "(46, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.545e-03, tolerance: 4.294e-04\n",
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m trial_no, env_no, time:  0 0 7.259821653366089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e-03, tolerance: 5.233e-04\n",
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e-02, tolerance: 5.233e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m trial_no, env_no, time:  0 1 11.779797077178955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.156e-02, tolerance: 7.345e-04\n",
      "\u001b[2m\u001b[36m(pid=183502)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m trial_no, env_no, time:  0 2 16.17482900619507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.810e-04, tolerance: 5.551e-04\n",
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.052e-02, tolerance: 5.551e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183502)\u001b[0m trial_no, env_no, time:  1 0 17.727818250656128\n",
      "\u001b[2m\u001b[36m(pid=183497)\u001b[0m trial_no, env_no, time:  0 3 20.606363534927368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183489)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183489)\u001b[0m trial_no, env_no, time:  2 0 27.959585666656494\n",
      "\u001b[2m\u001b[36m(pid=183502)\u001b[0m trial_no, env_no, time:  1 1 32.497132778167725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183501)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183501)\u001b[0m trial_no, env_no, time:  3 0 37.69484734535217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183504)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183502)\u001b[0m trial_no, env_no, time:  1 2 46.908809423446655\n",
      "\u001b[2m\u001b[36m(pid=183504)\u001b[0m trial_no, env_no, time:  4 0 47.42886686325073\n",
      "\u001b[2m\u001b[36m(pid=183489)\u001b[0m trial_no, env_no, time:  2 1 53.24818968772888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183491)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183491)\u001b[0m trial_no, env_no, time:  5 0 57.50912261009216\n",
      "\u001b[2m\u001b[36m(pid=183502)\u001b[0m trial_no, env_no, time:  1 3 61.51010060310364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m trial_no, env_no, time:  6 0 67.71304368972778\n",
      "\u001b[2m\u001b[36m(pid=183501)\u001b[0m trial_no, env_no, time:  3 1 72.61735773086548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183499)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183499)\u001b[0m trial_no, env_no, time:  7 0 77.55678367614746\n",
      "\u001b[2m\u001b[36m(pid=183489)\u001b[0m trial_no, env_no, time:  2 2 78.31124806404114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183494)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183494)\u001b[0m trial_no, env_no, time:  8 0 88.17254638671875\n",
      "\u001b[2m\u001b[36m(pid=183504)\u001b[0m trial_no, env_no, time:  4 1 92.09637212753296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183500)\u001b[0m  /opt/anaconda3/lib/python3.7/site-packages/ray/workers/default_worker.py:289: UserWarning:The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183500)\u001b[0m trial_no, env_no, time:  9 0 97.97588872909546\n",
      "\u001b[2m\u001b[36m(pid=183489)\u001b[0m trial_no, env_no, time:  2 3 103.30944776535034\n",
      "\u001b[2m\u001b[36m(pid=183501)\u001b[0m trial_no, env_no, time:  3 2 107.25847029685974\n",
      "\u001b[2m\u001b[36m(pid=183491)\u001b[0m trial_no, env_no, time:  5 1 112.24843573570251\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m trial_no, env_no, time:  6 1 132.69944310188293\n",
      "\u001b[2m\u001b[36m(pid=183504)\u001b[0m trial_no, env_no, time:  4 2 136.6447775363922\n",
      "\u001b[2m\u001b[36m(pid=183501)\u001b[0m trial_no, env_no, time:  3 3 142.08489155769348\n",
      "\u001b[2m\u001b[36m(pid=183499)\u001b[0m trial_no, env_no, time:  7 1 152.27337288856506\n",
      "\u001b[2m\u001b[36m(pid=183491)\u001b[0m trial_no, env_no, time:  5 2 166.83520698547363\n",
      "\u001b[2m\u001b[36m(pid=183494)\u001b[0m trial_no, env_no, time:  8 1 173.5285930633545\n",
      "\u001b[2m\u001b[36m(pid=183504)\u001b[0m trial_no, env_no, time:  4 3 181.1926670074463\n",
      "\u001b[2m\u001b[36m(pid=183500)\u001b[0m trial_no, env_no, time:  9 1 192.93099546432495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.600e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.489e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.205e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.331e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.457e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.131e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.130e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.449e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.129e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.328e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.445e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.216e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.128e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.326e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.437e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.126e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.433e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.324e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.429e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.390e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.110e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.205e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.112e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.101e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.092e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.188e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.283e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.079e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.269e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.074e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.068e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.258e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.155e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.046e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.147e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+00, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.040e+00, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.022e+00, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.644e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.550e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+00, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.116e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+00, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.728e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.789e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.737e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.057e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.421e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.239e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.122e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.929e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.049e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.658e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.073e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.538e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.152e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.090e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.961e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.273e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.869e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.351e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.188e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.298e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.801e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.749e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.736e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.341e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.686e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.438e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.416e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.181e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.553e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.121e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.930e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.672e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.828e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.434e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e-01, tolerance: 5.161e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.414e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.833e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.580e-01, tolerance: 5.422e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.235e-01, tolerance: 4.914e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e-01, tolerance: 5.353e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.313e-01, tolerance: 6.249e-02\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m  /home/mchowdh5/.local/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning:Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.647e-02, tolerance: 6.249e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m trial_no, env_no, time:  6 2 197.71308398246765\n",
      "\u001b[2m\u001b[36m(pid=183491)\u001b[0m trial_no, env_no, time:  5 3 221.38346529006958\n",
      "\u001b[2m\u001b[36m(pid=183499)\u001b[0m trial_no, env_no, time:  7 2 226.79539227485657\n",
      "\u001b[2m\u001b[36m(pid=183494)\u001b[0m trial_no, env_no, time:  8 2 258.4651837348938\n",
      "\u001b[2m\u001b[36m(pid=183503)\u001b[0m trial_no, env_no, time:  6 3 262.55810356140137\n",
      "\u001b[2m\u001b[36m(pid=183500)\u001b[0m trial_no, env_no, time:  9 2 287.7391264438629\n",
      "\u001b[2m\u001b[36m(pid=183499)\u001b[0m trial_no, env_no, time:  7 3 301.31370973587036\n",
      "\u001b[2m\u001b[36m(pid=183494)\u001b[0m trial_no, env_no, time:  8 3 343.4919264316559\n",
      "\u001b[2m\u001b[36m(pid=183500)\u001b[0m trial_no, env_no, time:  9 3 382.6340436935425\n"
     ]
    }
   ],
   "source": [
    "## 10 trials, \n",
    "## train on 3 envs test on remaining 1 env,\n",
    "## 3 models (regular, PCA, Siamese)\n",
    "\n",
    "## extra:\n",
    "##     1. train with 768 pretrained model (abstract len emb depends on PCA(768) on 90%)\n",
    "##     *2. use best model based on training loss (with struct_code 0 (simple) and 1 (complex))\n",
    "##     *3. use v8 (0- simple/PCA, solo, 768) struct\n",
    "##     *4. use v7 (1- complex, solo, 768) struct\n",
    "##     5. use v9 (simp+comp, solo env, 768)\n",
    "##     6. use v10 (simp+comp, solo env, 24)\n",
    "##     7. use v11 (simp+comp, beef env, 768)\n",
    "##     8. use v_12_3to1by24 (simp+comp, 3:1 env, 24)\n",
    "##     9. use v_13_3to1by768 (simp+comp, 3:1 env, 768)\n",
    "\n",
    "## imports\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline, AutoModelForMaskedLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader    \n",
    "import torchvision.utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import random\n",
    "# from pytorch_lightning.core.lightning import LightningModule\n",
    "# from pytorch_lightning import Trainer\n",
    "# import pytorch_lightning as pl\n",
    "# from ray_lightning import RayPlugin, RayShardedPlugin\n",
    "import ray\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import pickle as pk\n",
    "import time\n",
    "import utils\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from pprint import pprint\n",
    "\n",
    "import nltk, sklearn\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "\n",
    "## classes\n",
    "class SiameseNetwork(torch.nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding, use_irm=False, n_hidden_node=32, struct_code=0):\n",
    "        '''\n",
    "            struct_code {0=simple, 1=comple} structure\n",
    "        '''\n",
    "        \n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.use_irm = use_irm\n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.n_hidden_node = n_hidden_node\n",
    "        #-----------change_1\n",
    "        if struct_code == 0:\n",
    "            self.nn_reg = nn.Sequential(\n",
    "                nn.Linear(self.len_embedding, self.abstract_len_embedding),\n",
    "            )\n",
    "        elif struct_code == 1:\n",
    "            self.nn_reg = nn.Sequential(\n",
    "                nn.Linear(self.len_embedding, self.n_hidden_node),nn.ReLU(inplace=True),nn.BatchNorm1d(self.n_hidden_node),            \n",
    "                nn.Linear(self.n_hidden_node, int(self.n_hidden_node/4)),nn.ReLU(inplace=True),nn.BatchNorm1d(int(self.n_hidden_node/4)),nn.Dropout(p=0.2),\n",
    "                nn.Linear(int(self.n_hidden_node/4), self.abstract_len_embedding),\n",
    "            )\n",
    "        else:\n",
    "            self.nn_reg = nn.Sequential(\n",
    "                nn.Linear(self.len_embedding, self.abstract_len_embedding),\n",
    "            )            \n",
    "        #-----------change_1\n",
    "        self.nn_final_reg = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding * 2, self.n_hidden_node),nn.ReLU(inplace=True),nn.BatchNorm1d(self.n_hidden_node),\n",
    "            nn.Linear(self.n_hidden_node, int(self.n_hidden_node/4)),nn.ReLU(inplace=True),nn.BatchNorm1d(int(self.n_hidden_node/4)),nn.Dropout(p=0.2),\n",
    "            nn.Linear(int(self.n_hidden_node/4), 1),\n",
    "        )\n",
    "\n",
    "    def forward_reg(self, x):\n",
    "        output = self.nn_reg(x)\n",
    "        return output\n",
    "\n",
    "    def forward_final_reg(self, x):\n",
    "        output = self.nn_final_reg(x)\n",
    "        return output\n",
    "\n",
    "    def forward(self, fp1, fp2):\n",
    "        a = self.forward_reg(fp1)\n",
    "        b = self.forward_reg(fp2)\n",
    "        x = torch.cat([a, b], dim=1)  # hstack\n",
    "        output = self.forward_final_reg(x)\n",
    "        return output\n",
    "\n",
    "    def compute_penalty(self, losses, dummy_w):\n",
    "        g = grad(losses, dummy_w, create_graph=True)[0]\n",
    "        r = g.pow(2)\n",
    "        return r\n",
    "\n",
    "## functions\n",
    "\n",
    "def get_secondary_env(env=None):\n",
    "    x_e, y_e = env[0].numpy(), env[1].numpy()\n",
    "\n",
    "    list_primary_feature, list_primary_target = [], []\n",
    "    list_secondary_feature, list_secondary_target = [], []\n",
    "\n",
    "    for i in range(x_e.shape[0]):\n",
    "        list_primary_feature.append(x_e[i])\n",
    "        list_primary_target.append(y_e[i])\n",
    "        i += 1\n",
    "\n",
    "    for i in range(len(list_primary_feature)):\n",
    "        for j in range(len(list_primary_feature)):\n",
    "            if i == j:\n",
    "                pass\n",
    "            else:\n",
    "                a = list_primary_feature[i]\n",
    "                b = list_primary_feature[j]\n",
    "                sf = np.hstack((a, b))\n",
    "                st = list_primary_target[i] - list_primary_target[j]\n",
    "                list_secondary_feature.append(sf)\n",
    "                list_secondary_target.append(st)\n",
    "    array_secondary_feature = np.array(list_secondary_feature, dtype='float32')\n",
    "    array_secondary_target = np.array(list_secondary_target, dtype='float32').reshape((-1, 1))\n",
    "    senv = torch.from_numpy(array_secondary_feature), torch.from_numpy(array_secondary_target)\n",
    "    return senv\n",
    "\n",
    "#### 1. seperate feature target for 6 envs (6 files in v11/datasets/)\n",
    "\n",
    "dir_datasets = 'datasets/' ## 'datasets/v2/'\n",
    "\n",
    "df_1_energy = pd.read_excel(dir_datasets + 'file_1.xlsx', sheet_name=0) ## energy sheet\n",
    "m_1_energy = df_1_energy.values[1:]\n",
    "m_1_name = m_1_energy[:,[0]]\n",
    "m_1_smiles = m_1_energy[:,[1]]\n",
    "m_1_energy_envs = m_1_energy[:,[2, 3, 4, 5]]\n",
    "for env_no in range(m_1_energy_envs.shape[1]):\n",
    "    m_1_name_smiles = np.hstack((m_1_name, m_1_smiles))\n",
    "    feature_target = np.hstack((m_1_name_smiles, m_1_energy_envs[:, [env_no]]))\n",
    "    np.savetxt(dir_datasets + 'smiles_vs_energy_env_' + str(env_no) + '.csv', feature_target, delimiter = \",\", fmt='%s')\n",
    "\n",
    "#### 2. use 1 model (model to generate embedding, here we use from extrapolation paper) for each of these envs (6 additional feature-target files in datasets/)\n",
    "\n",
    "## funtion to generate pretrained embedding from SMILE notations\n",
    "\n",
    "## change_2 : change in v10(24) from v9(768) to accomodate manual 24 length embedding \n",
    "def get_embed_from_smiles(list_species_smiles, emb_style='auto_768'):\n",
    "    if emb_style=='manual_24':\n",
    "        list_emb = []\n",
    "        for i, s1 in enumerate(smiles):\n",
    "            try:\n",
    "                s2 = utils.convertNewSmilesToOldSmiles(s1)\n",
    "                s3 = utils.readSmilesToFingerprints(s2)\n",
    "            except Exception as e:\n",
    "                print(env_no, i, e)\n",
    "                s3 = ['-'] * 24\n",
    "            list_emb.append(s3)    \n",
    "        return np.array(list_emb)\n",
    "    else:\n",
    "        ## --------------- this is commented out in the server ----------------------- ##\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/chEMBL26_smiles_v2\")\n",
    "        model = AutoModel.from_pretrained(\"mrm8488/chEMBL26_smiles_v2\")\n",
    "        # Load the model into the GPU if avilabile and switch to inference mode\n",
    "        fe = pipeline('feature-extraction', model=model, tokenizer=tokenizer,device=0)\n",
    "        sequences_Example = list_species_smiles\n",
    "        embedding_1 = fe(sequences_Example)\n",
    "        n1, n2, n3 = len(embedding_1), len(embedding_1[0]), len(embedding_1[0][0])\n",
    "        embedding_2 = np.zeros((n1, n3))\n",
    "        list_embedding = []\n",
    "        for i, e1 in enumerate(embedding_1):\n",
    "            e2 = np.array(e1).mean(axis=0)        \n",
    "            embedding_2[i, :] = e2\n",
    "        embedding_2 = np.array(embedding_2)                    \n",
    "        return embedding_2\n",
    "\n",
    "dir_datasets = 'datasets/'\n",
    "for env_no in range(4): \n",
    "    file_name = dir_datasets + 'smiles_vs_energy_env_' + str(env_no) + '.csv'\n",
    "    df = pd.read_csv(file_name, sep=\",\", header=None) \n",
    "    m = df.values\n",
    "    smiles = [row[1] for row in m] ## 1 for smiles ==> (row[0],row[1],row[2]) == (name, smiles, energy)\n",
    "    \n",
    "    array_emb = get_embed_from_smiles(smiles, emb_style='auto_768') ## change_2 : change in v10(24) from v9(768) to accomodate manual 24 length embedding     \n",
    "    feature_target = np.hstack((array_emb, m[:,[2]])) ## index 2 used here for energy\n",
    "    \n",
    "    print(feature_target.shape)\n",
    "    np.savetxt('datasets/embedding_vs_energy_env_' + str(env_no) + '.csv', feature_target, delimiter = \",\", fmt='%s')\n",
    "#     print()\n",
    "\n",
    "## change_2 : change in v10(24) from v9(768) to accomodate manual 24 length embedding \n",
    "## skip invalid samples => index in each env [41,41,41,41,'-',9] for manual_24\n",
    "## skip invalid samples => index in each env ['-','-','-','-','-','-'] for auto_768\n",
    "list_skip_index = ['-','-','-','-']\n",
    "dir_datasets = 'datasets/'\n",
    "for env_no in range(4): \n",
    "    data = genfromtxt(dir_datasets + 'embedding_vs_energy_env_' + str(env_no) + '.csv', delimiter=',', dtype='float32')\n",
    "    skip_index = list_skip_index[env_no]\n",
    "    if skip_index == '-':\n",
    "        feature = data[:, 0:-1]\n",
    "        target = data[:, [-1]]\n",
    "    elif type(skip_index)== type(0):\n",
    "        feature = np.vstack((data[:skip_index, 0:-1], data[skip_index+1:, 0:-1]))\n",
    "        target = np.vstack((data[:skip_index, [-1]], data[skip_index+1:, [-1]]))\n",
    "    else:\n",
    "        print('Error!!!')\n",
    "    feature_target = np.hstack((feature, target))\n",
    "    print(feature_target.shape)\n",
    "    np.savetxt('datasets/filtered_embedding_vs_energy_env_' + str(env_no) + '.csv', feature_target, delimiter = \",\", fmt='%s')\n",
    "\n",
    "## reading data for Siamese\n",
    "\n",
    "dir_datasets = 'datasets/'\n",
    "#\n",
    "df_1_energy = pd.read_excel(dir_datasets + 'file_1.xlsx', sheet_name=0) ## energy sheet\n",
    "df_1_feature = genfromtxt(dir_datasets + 'embedding_vs_energy_env_0.csv', delimiter=',', dtype='float32')\n",
    "#\n",
    "m_1_energy = df_1_energy.values[1:]\n",
    "m_1_feature = df_1_feature[:,list(range(0,768))]\n",
    "#\n",
    "print(m_1_energy.shape)\n",
    "print(m_1_feature.shape)\n",
    "\n",
    "## random rough code\n",
    "\n",
    "# df_1_energy\n",
    "\n",
    "#### 3. use 10 trials, 6 envs, 3 models to evaluate the performance\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True, num_cpus=16) ## detects automatically: num_cpus=64\n",
    "\n",
    "## TBD update this function\n",
    "## functions\n",
    "\n",
    "def get_best_models(\n",
    "    m_1_feature=None, m_1_energy=None,\n",
    "    len_embedding=None, abstract_len_embedding=None, num_iterations=None, random_state=None,\n",
    "    trial_no=None, env_no=None\n",
    "):\n",
    "        \n",
    "    ## train: target-feature\n",
    "    #\n",
    "    list_env = [0,1,2,3] ## column index in m_1_energy [14,15,16,17] \n",
    "    list_env_remain = []\n",
    "    for env in list_env:\n",
    "        if env != env_no:\n",
    "            list_env_remain.append(env)\n",
    "    list_env_remain_index = [env_remain+2 for env_remain in list_env_remain]\n",
    "    skip_index_3to1 = None\n",
    "    #\n",
    "    data_feature_train = m_1_feature\n",
    "    data_target_train = np.array(m_1_energy[:,list_env_remain_index], dtype='float32')\n",
    "    #\n",
    "    if skip_index_3to1 is not None:\n",
    "        data_feature_train = np.vstack((data_feature_train[:skip_index_3to1, :], data_feature_train[skip_index_3to1+1:, :]))\n",
    "        data_target_train = np.vstack((data_target_train[:skip_index_3to1, :], data_target_train[skip_index_3to1+1:, :]))  \n",
    "    else:\n",
    "        pass\n",
    "    #\n",
    "    file1 = open('logger.log', 'a+')  \n",
    "    file1.writelines(\n",
    "        'trial_no, env_no, list_env_remin_index, data_target_train_shape: ' \\\n",
    "        + str(trial_no) + str(env_no) + str(list_env_remain_index) + str(data_target_train.shape) + '\\n\\n'\n",
    "    )\n",
    "    file1.close()                    \n",
    "    #\n",
    "\n",
    "    \n",
    "    ## environments: primary\n",
    "    environments = []\n",
    "    for i in range(data_target_train.shape[1]):\n",
    "        env = torch.from_numpy(data_feature_train[0:]), torch.from_numpy(data_target_train[0:, [i]])\n",
    "        environments.append(env)\n",
    "#     print(len(environments), environments[0][0].shape, environments[0][1].shape)\n",
    "    \n",
    "    ## environments: secondary\n",
    "    senvironments = []\n",
    "    for env in environments:\n",
    "        senv = get_secondary_env(env=env)\n",
    "        senvironments.append(senv)\n",
    "#     print(len(senvironments), senvironments[0][0].shape, senvironments[0][1].shape)  \n",
    "    \n",
    "    ## model siamese\n",
    "    list_model_info = []\n",
    "    best_model_info, best_loss_siamese = (None, None, None, None), math.inf\n",
    "    #-----------change_1    \n",
    "    for _n_hidden_node in [128]: ## [256,128,64,32] ## hint: select something that is divisible by 4  \n",
    "    #-----------change_1\n",
    "        for _lr in [1e-4, 1e-3, 1e-2, 1e-1, 1]: ## [1e-4, 1e-3, 1e-2, 1e-1, 1] \n",
    "            for _struct_code in [0]: ## [0,1]\n",
    "                model_siamese = SiameseNetwork(\n",
    "                    len_embedding, abstract_len_embedding, use_irm=False, n_hidden_node=_n_hidden_node,\n",
    "                    struct_code=_struct_code\n",
    "                )\n",
    "                optimizer_siamese = torch.optim.Adam(model_siamese.parameters(), lr=_lr)\n",
    "                \n",
    "                loss_siamese = None\n",
    "                for epoch in range(num_iterations):\n",
    "                    error_siamese = 0\n",
    "                    for x, y in senvironments:\n",
    "                        p = torch.randperm(len(x))\n",
    "                        x_e = x[p]\n",
    "                        y_e = y[p]\n",
    "                        fp1 = x_e[:, list(range(0, len_embedding, 1))]\n",
    "                        fp2 = x_e[:, list(range(len_embedding, 2 * len_embedding, 1))]\n",
    "                        y_pred_siamese = model_siamese(fp1, fp2) \n",
    "                        error_e_siamese = model_siamese.loss(y_pred_siamese, y_e)\n",
    "                        error_siamese += error_e_siamese\n",
    "                        \n",
    "                    error_siamese = error_siamese/len(senvironments)\n",
    "                    loss_siamese = 1 * error_siamese \n",
    "\n",
    "                    optimizer_siamese.zero_grad() ## clear buffer   \n",
    "                    loss_siamese.backward() ## calculate gradient for all params\n",
    "                    optimizer_siamese.step() ## update parameters using calculated gradients\n",
    "                \n",
    "                if loss_siamese < best_loss_siamese:\n",
    "                    best_model_info = (_n_hidden_node, _lr, _struct_code, model_siamese)\n",
    "                    best_loss_siamese = loss_siamese\n",
    "                file1 = open('logger.log', 'a+')  \n",
    "                file1.writelines(\n",
    "                    'trial_no, env_no, n_hidden_node, lr, struct_code, loss_siamese, best_loss_siamese: ' \\\n",
    "                    + str(trial_no) + str(env_no) + str(_n_hidden_node) + str(_lr) + str(_struct_code) \\\n",
    "                    + str(loss_siamese) + str(best_loss_siamese) + '\\n\\n'\n",
    "                )\n",
    "                file1.close()                \n",
    "                model_info = (_n_hidden_node, _lr, _struct_code, model_siamese)\n",
    "                list_model_info.append(model_info)\n",
    "             \n",
    "    return best_model_info, list_model_info        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@ray.remote(num_returns=1)\n",
    "def get_result(\n",
    "    st, trial_no, list_env, dir_datasets, should_standardize, \n",
    "    m_1_feature, m_1_energy, \n",
    "    len_embedding, num_iterations, pca_n_percent\n",
    "):\n",
    "    for env_no in list_env:\n",
    "        d_result = {}        \n",
    "        data = genfromtxt(dir_datasets + 'filtered_embedding_vs_energy_env_' + str(env_no) + '.csv', delimiter=',', dtype='float32')\n",
    "        feature = data[:, 0:-1]\n",
    "        target = data[:, [-1]]\n",
    "        if should_standardize:\n",
    "            scaler = StandardScaler().fit(feature)\n",
    "            feature = scaler.transform(feature)\n",
    "            \n",
    "        #####################################################################################################################################            \n",
    "        ## model 1: regular\n",
    "        model_name = 'regular' ## use the embeddings as it is\n",
    "        feature_regular, target_regular = feature, target\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            feature_regular, target_regular, test_size=0.33, random_state=trial_no\n",
    "        )        \n",
    "        ##\n",
    "        trainX, testX, trainY, testY = X_train, X_test, y_train.ravel(), y_test.ravel()\n",
    "        mlrun = utils.MLPredsByCV(cross_validation_split_no = 5)   \n",
    "        for alg in ['ridge','lasso','elastic','krr','svr']: ## ['ridge','lasso','elastic','krr','svr','gp']:\n",
    "            if alg == 'svr':\n",
    "                errors = mlrun.SVR_CV(trainX, testX, trainY, testY)\n",
    "            elif alg == 'krr':\n",
    "                errors = mlrun.KRR_CV(trainX, testX, trainY, testY)\n",
    "            elif alg == 'ridge':\n",
    "                errors = mlrun.Ridge_CV(trainX, testX, trainY, testY)\n",
    "            elif alg == 'lasso':\n",
    "                errors = mlrun.Lasso_CV(trainX, testX, trainY, testY)\n",
    "            elif alg == 'elastic':\n",
    "                errors = mlrun.Elastic_CV(trainX, testX, trainY, testY)\n",
    "            error = np.mean(errors)\n",
    "            key = (str(trial_no), str(env_no), str(model_name), str(alg))\n",
    "            d_result[key] = error\n",
    "        file1 = open('logger.log', 'a+')  \n",
    "        file1.writelines(\n",
    "            'regular: time, trial_no, env_no, model_name: ' \\\n",
    "            + str(time.time()-st) + '=>  ' + str(trial_no) + ', ' \\\n",
    "            + str(env_no) + ', ' + str(model_name) + '\\n\\n'\n",
    "        )\n",
    "        file1.close()            \n",
    "        \n",
    "        ##################################################################################################################################### \n",
    "        ## model 2: PCA\n",
    "        model_name = 'PCA' ## use the transformed embeddings by PCA\n",
    "        pca_dump_name = dir_datasets + 'pca_' + str(env_no) + '.pkl'\n",
    "        if should_standardize:\n",
    "            pca_dump_name = dir_datasets + 'pca_std_' + str(env_no) + '.pkl'                    \n",
    "        #-----------change_1\n",
    "        pca = PCA(n_components=pca_n_percent) ## e.g. 24 => 6 or other number of components\n",
    "        feature_train, feature_test, target_train, target_test = train_test_split(\n",
    "            feature, target, test_size=0.33, random_state=trial_no\n",
    "        )    \n",
    "        pca.fit(feature_train)\n",
    "        ## pickle dump\n",
    "        pk.dump(pca, open(pca_dump_name,\"wb\"))\n",
    "        ## later reload the pickle file\n",
    "        time.sleep(trial_no*5)        \n",
    "        pca = pk.load(open(pca_dump_name,\"rb\"))\n",
    "        #-----------change_1\n",
    "        pca_n_components = pca.n_components_\n",
    "        file1 = open('logger.log', 'a+')  \n",
    "        file1.writelines('trial_no, env_no, pca_n_components: ' + str(trial_no) + ',' + str(env_no) + ', ' + str(pca_n_components) + '\\n\\n')\n",
    "        file1.close()            \n",
    "\n",
    "        feature_pca, target_pca = pca.transform(feature), target\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            feature_pca, target_pca, test_size=0.33, random_state=trial_no\n",
    "        )    \n",
    "        ##\n",
    "        trainX, testX, trainY, testY = X_train, X_test, y_train.ravel(), y_test.ravel()\n",
    "        mlrun = utils.MLPredsByCV(cross_validation_split_no = 5)                \n",
    "        for alg in ['ridge','lasso','elastic','krr','svr']: ## ['ridge','lasso','elastic','krr','svr','gp']:\n",
    "            if alg == 'svr':\n",
    "                errors = mlrun.SVR_CV(trainX, testX, trainY, testY)\n",
    "            elif alg == 'krr':\n",
    "                errors = mlrun.KRR_CV(trainX, testX, trainY, testY)\n",
    "            elif alg == 'ridge':\n",
    "                errors = mlrun.Ridge_CV(trainX, testX, trainY, testY)\n",
    "            elif alg == 'lasso':\n",
    "                errors = mlrun.Lasso_CV(trainX, testX, trainY, testY)\n",
    "            elif alg == 'elastic':\n",
    "                errors = mlrun.Elastic_CV(trainX, testX, trainY, testY)\n",
    "            error = np.mean(errors)\n",
    "            key = (str(trial_no), str(env_no), str(model_name), str(alg))\n",
    "            d_result[key] = error\n",
    "        file1 = open('logger.log', 'a+')  \n",
    "        file1.writelines(\n",
    "            'pca: time, trial_no, env_no, model_name: ' \\\n",
    "            + str(time.time()-st) + '=>  ' + str(trial_no) + ', ' \\\n",
    "            + str(env_no) + ', ' + str(model_name) + '\\n\\n'\n",
    "        )\n",
    "        file1.close()            \n",
    "            \n",
    "        #####################################################################################################################################    \n",
    "        ## model 3: Siamese\n",
    "        pca_dump_name = dir_datasets + 'pca_' + str(env_no) + '.pkl'\n",
    "        if should_standardize:\n",
    "            pca_dump_name = dir_datasets + 'pca_std_' + str(env_no) + '.pkl' \n",
    "        time.sleep(trial_no*5)            \n",
    "        pca = pk.load(open(pca_dump_name,\"rb\"))\n",
    "        pca_n_components = pca.n_components_\n",
    "        best_model_info, list_model_info = get_best_models(\n",
    "            m_1_feature=m_1_feature, m_1_energy=m_1_energy,\n",
    "            len_embedding=len_embedding, abstract_len_embedding=pca_n_components,\n",
    "            num_iterations=num_iterations, random_state=trial_no, trial_no=trial_no, env_no=env_no\n",
    "        )                            \n",
    "    \n",
    "        for model_info in [best_model_info]:            \n",
    "            _nhn, _lr, _sc, model_siamese = model_info[0], model_info[1], model_info[2], model_info[3]  \n",
    "            \n",
    "            # model_name = 'Siamese_' + str(_nhn) + '_' + str(_lr) + '_' + str(_sc) ## use the transformed embeddings by Siamese\n",
    "            model_name = 'Siamese'            \n",
    "            feature_siamese, target_siamese = model_siamese.forward_reg(torch.from_numpy(feature)).detach().numpy(), target \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                feature_siamese, target_siamese, test_size=0.33, random_state=trial_no\n",
    "            )    \n",
    "        #-----------------------------------------------------------------------------------        \n",
    "        #\n",
    "            trainX, testX, trainY, testY = X_train, X_test, y_train.ravel(), y_test.ravel()\n",
    "            mlrun = utils.MLPredsByCV(cross_validation_split_no = 5)                \n",
    "            for alg in ['ridge','lasso','elastic','krr','svr']: ## ['ridge','lasso','elastic','krr','svr','gp']:\n",
    "                if alg == 'svr':\n",
    "                    errors = mlrun.SVR_CV(trainX, testX, trainY, testY)\n",
    "                elif alg == 'krr':\n",
    "                    errors = mlrun.KRR_CV(trainX, testX, trainY, testY)\n",
    "                elif alg == 'ridge':\n",
    "                    errors = mlrun.Ridge_CV(trainX, testX, trainY, testY)\n",
    "                elif alg == 'lasso':\n",
    "                    errors = mlrun.Lasso_CV(trainX, testX, trainY, testY)\n",
    "                elif alg == 'elastic':\n",
    "                    errors = mlrun.Elastic_CV(trainX, testX, trainY, testY)\n",
    "                error = np.mean(errors)\n",
    "                key = (str(trial_no), str(env_no), str(model_name), str(alg))\n",
    "                d_result[key] = error\n",
    "            file1 = open('logger.log', 'a+')  \n",
    "            file1.writelines('siamese: time, trial_no, env_no, model_name: ' + str(time.time()-st) + '=>  ' + str(trial_no) + ', ' + str(env_no) + ', ' + str(model_name) + '\\n\\n')\n",
    "            file1.close()            \n",
    "\n",
    "        #####################################################################################################################################\n",
    "        ## model 4: SiameseIRM\n",
    "        #####################################################################################################################################     \n",
    "        print('trial_no, env_no, time: ', trial_no, env_no, time.time()-st)    \n",
    "        \n",
    "        with open('datasets/d_result_' + str(trial_no) + '_' + str(env_no) + '.pickle', 'wb') as handle: \n",
    "            pk.dump(d_result, handle, protocol=pk.HIGHEST_PROTOCOL)\n",
    "    return 0\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #-----------change_1\n",
    "    num_trials = 10 ## should be 10\n",
    "    list_env = [0,1,2,3] ## should be [0,1,2,3]\n",
    "    num_iterations = 2 ## 1000 ## should be (500 or 1000) for train on BEEF (extrapolation) or (5000 or 10000) for train on individual env (intrapolation)\n",
    "    #-----------change_1\n",
    "    dir_datasets = 'datasets/'\n",
    "    should_standardize = False\n",
    "    len_embedding=768 ## change_2\n",
    "    pca_n_percent=0.90 ## change_2\n",
    "    ## main_1\n",
    "\n",
    "    st = time.time()\n",
    "    list_result_id = []\n",
    "    for trial_no in range(num_trials):\n",
    "        result_id = get_result.remote(\n",
    "            st, trial_no, list_env, dir_datasets, should_standardize, \n",
    "            m_1_feature, m_1_energy,\n",
    "            len_embedding, num_iterations, pca_n_percent\n",
    "        )\n",
    "        list_result_id.append(result_id)\n",
    "    list_result = ray.get(list_result_id)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

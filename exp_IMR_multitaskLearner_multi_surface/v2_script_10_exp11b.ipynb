{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6705d43-9a3c-40c9-bdc4-0c8cd36a686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## created from (exp9e => exp11a)\n",
    "## exp_name = 'exp11b'\n",
    "## 1e-4 x 10000\n",
    "## 1024 => 512 => 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff4bfa4d-62ba-4ec4-96f8-90a46b6ad260",
   "metadata": {},
   "outputs": [],
   "source": [
    "## install\n",
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e66501-338b-45e6-b5de-9647910c333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import DataParallel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7ca896-d159-4718-b2de-8eee708cd5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8b90843850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## variables\n",
    "seed = 42\n",
    "ratio_test = 0.2\n",
    "exp_name = 'exp_11b' ## change\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "curdir = '' ## '/curdir/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f5615c-b8d6-4d99-9796-4f8e9986e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction='mean')\n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.5)),\n",
    "            \n",
    "            nn.Linear(int(self.len_embedding*0.5), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "        \n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c82f46c-15a1-41f4-a297-95c75d29acbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function\n",
    "\n",
    "def penalty(logits, y, device):\n",
    "    scale = torch.tensor(1.).to(device).requires_grad_()\n",
    "    loss = nn.L1Loss(reduction='mean')(logits * scale, y)\n",
    "    grad = autograd.grad(loss, [scale], create_graph=True)[0]\n",
    "    return torch.sum(grad**2)\n",
    "\n",
    "def get_model_invariant(train_loader1, train_loader2, len_embedding, abstract_len_embedding):\n",
    "    print(f'len_embedding: {len_embedding}, abstract_len_embedding: {abstract_len_embedding}')\n",
    "    _lr, num_iterations = 1e-4, 10000\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "    model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "    if torch.cuda.is_available():\n",
    "        model_invariant = DataParallel(model_invariant)\n",
    "    model_invariant.to(device)\n",
    "    optimizer_invariant = torch.optim.Adam(model_invariant.parameters(), lr=_lr)\n",
    "    \n",
    "    model_invariant.train()\n",
    "    for epoch in range(num_iterations):\n",
    "        total_loss = 0.0\n",
    "        train_loader1_cycle = cycle(train_loader1)\n",
    "        train_loader2_cycle = cycle(train_loader2)\n",
    "        max_batches = max(len(train_loader1), len(train_loader2))\n",
    "        for i in range(max_batches):\n",
    "            \n",
    "            data1 = next(train_loader1_cycle)\n",
    "            data2 = next(train_loader2_cycle)\n",
    "                    \n",
    "            inputs1, labels1 = data1[0].to(device), data1[1].to(device)\n",
    "            outputs1 = model_invariant(inputs1, dataset_id=1).squeeze()\n",
    "            loss1 = model_invariant.module.loss(outputs1, labels1) if isinstance(model_invariant, DataParallel) else model_invariant.loss(outputs1, labels1)\n",
    "            penalty1 = penalty(outputs1, labels1, device)\n",
    "            \n",
    "            inputs2, labels2 = data2[0].to(device), data2[1].to(device)\n",
    "            outputs2 = model_invariant(inputs2, dataset_id=2).squeeze()\n",
    "            loss2 = model_invariant.module.loss(outputs2, labels2) if isinstance(model_invariant, DataParallel) else model_invariant.loss(outputs2, labels2)\n",
    "            penalty2 = penalty(outputs2, labels2, device)\n",
    "        \n",
    "            optimizer_invariant.zero_grad()        \n",
    "            # (loss1 + loss2).backward()            \n",
    "            (loss1 + penalty1 + loss2 + penalty2).backward()\n",
    "            optimizer_invariant.step()\n",
    "            \n",
    "            total_loss += (loss1.item() + loss2.item())\n",
    "            \n",
    "        if epoch%1==0:\n",
    "            with open(curdir + 'v2_script_10/logger_' + exp_name + '.log', 'a+') as file1:\n",
    "                file1.writelines(f'epoch: {epoch}, total_loss: {total_loss:.6f}\\n\\n')\n",
    "            \n",
    "        \n",
    "    return model_invariant.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24234968-c502-4ab2-aafb-89d89660c6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8750, 1024) (2188, 1024) (8750,) (2188,)\n",
      "(263890, 1024) (65973, 1024) (263890,) (65973,)\n"
     ]
    }
   ],
   "source": [
    "## cathub, imr, (MAE, r2)\n",
    "## ocp, imr, (MAE, r2)\n",
    "df1 = pd.read_pickle(f'{curdir}datasets/df_cathub_dpp_combined.pickle')\n",
    "X1 = df1.iloc[:, :-1].values\n",
    "y1 = df1['nre'].values\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=ratio_test, random_state=seed)\n",
    "df2 = pd.read_pickle(f'{curdir}datasets/df_ocp_dpp_combined.pickle')\n",
    "X2 = df2.iloc[:, :-1].values\n",
    "y2 = df2['energy'].values\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=ratio_test, random_state=seed)\n",
    "print(X_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape)\n",
    "print(X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f2bdbbf-fd79-4f89-a5d7-dd0a6b55ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = TensorDataset(torch.tensor(X_train1, dtype=torch.float32), torch.tensor(y_train1, dtype=torch.float32))\n",
    "train_data2 = TensorDataset(torch.tensor(X_train2, dtype=torch.float32), torch.tensor(y_train2, dtype=torch.float32))\n",
    "\n",
    "batch_size = 10000\n",
    "train_loader1 = DataLoader(train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_loader2 = DataLoader(train_data2, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91ed4bd-513a-47f7-9b08-6c138b8a381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader1), len(train_loader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75af5cda-e56f-4952-b574-f7cc6e550e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_embedding: 1024, abstract_len_embedding: 256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m abstract_len_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(len_embedding\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.25\u001b[39m)\n\u001b[1;32m      3\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2_script_10/model_invariant_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m exp_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model_invariant \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_invariant\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlen_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabstract_len_embedding\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model_invariant\u001b[38;5;241m.\u001b[39mstate_dict(), model_path)\n",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mget_model_invariant\u001b[0;34m(train_loader1, train_loader2, len_embedding, abstract_len_embedding)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_batches):\n\u001b[1;32m     27\u001b[0m     data1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(train_loader1_cycle)\n\u001b[0;32m---> 28\u001b[0m     data2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader2_cycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     inputs1, labels1 \u001b[38;5;241m=\u001b[39m data1[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device), data1[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     31\u001b[0m     outputs1 \u001b[38;5;241m=\u001b[39m model_invariant(inputs1, dataset_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_' + exp_name + '.pt'\n",
    "model_invariant = get_model_invariant(\n",
    "    train_loader1, train_loader2, \n",
    "    len_embedding, abstract_len_embedding\n",
    ")\n",
    "torch.save(model_invariant.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc693e8-2680-426f-819e-a0bbdc19e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ecd7d-9aaa-4e5d-8c69-178002fa5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_' + exp_name + '.pt'\n",
    "model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "model_invariant.load_state_dict(torch.load(model_path))\n",
    "model_invariant.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d7f2e-7cb5-4b92-8c1a-d3302692d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_invariant1 = model_invariant.encoder(torch.tensor(X_train1, dtype=torch.float32)).detach().numpy()\n",
    "X_test_invariant1 = model_invariant.encoder(torch.tensor(X_test1, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "lr = 0.2\n",
    "depth = 8\n",
    "n_est = 500\n",
    "model1 = xgb.XGBRegressor(learning_rate=lr, max_depth=depth, n_estimators=n_est)\n",
    "model1.fit(X_train_invariant1, y_train1)\n",
    "\n",
    "y_pred1 = model1.predict(X_test_invariant1)\n",
    "mae1 = mean_absolute_error(y_test1, y_pred1)\n",
    "r2score1 = r2_score(y_test1, y_pred1)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(y_test1, y_pred1, alpha=0.5)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title(f'(cathub, invariant)')\n",
    "plt.plot([y_test1.min(), y_test1.max()], [y_test1.min(), y_test1.max()], 'k--', lw=2)\n",
    "plt.show()\n",
    "print()\n",
    "print(f'X_train shape: {X_train1.shape}, X_test shape: {X_test1.shape}')\n",
    "print(f'y_train shape: {y_train1.shape}, y_test shape: {y_test1.shape}')\n",
    "print(f'train to test ratio: {1-ratio_test}:{ratio_test}')\n",
    "print(f'Mean Abs. Error: {mae1:.2f}')\n",
    "print(f'R2-score: {r2score1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ac593-a064-4b90-bdf7-939f93b82150",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_invariant2 = model_invariant.encoder(torch.tensor(X_train2, dtype=torch.float32)).detach().numpy()\n",
    "X_test_invariant2 = model_invariant.encoder(torch.tensor(X_test2, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "lr = 0.2\n",
    "depth = 8\n",
    "n_est = 500\n",
    "model2 = xgb.XGBRegressor(learning_rate=lr, max_depth=depth, n_estimators=n_est)\n",
    "model2.fit(X_train_invariant2, y_train2)\n",
    "\n",
    "y_pred2 = model2.predict(X_test_invariant2)\n",
    "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
    "r2score2 = r2_score(y_test2, y_pred2)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(y_test2, y_pred2, alpha=0.5)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title(f'(cathub, invariant)')\n",
    "plt.plot([y_test2.min(), y_test2.max()], [y_test2.min(), y_test2.max()], 'k--', lw=2)\n",
    "plt.show()\n",
    "print()\n",
    "print(f'X_train shape: {X_train2.shape}, X_test shape: {X_test2.shape}')\n",
    "print(f'y_train shape: {y_train2.shape}, y_test shape: {y_test2.shape}')\n",
    "print(f'train to test ratio: {1-ratio_test}:{ratio_test}')\n",
    "print(f'Mean Abs. Error: {mae2:.2f}')\n",
    "print(f'R2-score: {r2score2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c26fc1-53a4-42e4-8535-e7913da4dc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499558cf-62de-4ff4-b160-49e045e37150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba884d68-d037-4053-8c50-d2542c635b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c824e12-7b66-47d6-a006-b66c0f42f49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042acf24-cd63-4192-9694-743d8759ded2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56fa92-242e-4cb5-824a-1b73cf7b5b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d3d0f-1413-4e34-854a-6e268f2ccdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a19a2-206c-4012-a988-13f7560817da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

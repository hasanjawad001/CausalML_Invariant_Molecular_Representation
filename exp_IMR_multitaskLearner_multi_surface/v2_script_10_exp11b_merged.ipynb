{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8def7-a806-49ac-b29d-22eca79eed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## created from (exp9e => exp11a)\n",
    "## exp_name = 'exp11b'\n",
    "## 1e-4 x 10000\n",
    "## 1024 => 512 => 256\n",
    "\n",
    "## install\n",
    "# !pip install xgboost\n",
    "\n",
    "## import\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import DataParallel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import torch.autograd as autograd\n",
    "\n",
    "## variables\n",
    "seed = 42\n",
    "ratio_test = 0.2\n",
    "exp_name = 'exp_11b' ## change\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "curdir = '' ## '/curdir/'\n",
    "\n",
    "## class\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction='mean')\n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.5)),\n",
    "            \n",
    "            nn.Linear(int(self.len_embedding*0.5), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "        \n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "\n",
    "## function\n",
    "\n",
    "def penalty(logits, y, device):\n",
    "    scale = torch.tensor(1.).to(device).requires_grad_()\n",
    "    loss = nn.L1Loss(reduction='mean')(logits * scale, y)\n",
    "    grad = autograd.grad(loss, [scale], create_graph=True)[0]\n",
    "    return torch.sum(grad**2)\n",
    "\n",
    "def get_model_invariant(train_loader1, train_loader2, len_embedding, abstract_len_embedding):\n",
    "    print(f'len_embedding: {len_embedding}, abstract_len_embedding: {abstract_len_embedding}')\n",
    "    _lr, num_iterations = 1e-4, 10000\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "    model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "    if torch.cuda.is_available():\n",
    "        model_invariant = DataParallel(model_invariant)\n",
    "    model_invariant.to(device)\n",
    "    optimizer_invariant = torch.optim.Adam(model_invariant.parameters(), lr=_lr)\n",
    "    \n",
    "    model_invariant.train()\n",
    "    for epoch in range(num_iterations):\n",
    "        total_loss = 0.0\n",
    "        train_loader1_cycle = cycle(train_loader1)\n",
    "        train_loader2_cycle = cycle(train_loader2)\n",
    "        max_batches = max(len(train_loader1), len(train_loader2))\n",
    "        for i in range(max_batches):\n",
    "            \n",
    "            data1 = next(train_loader1_cycle)\n",
    "            data2 = next(train_loader2_cycle)\n",
    "                    \n",
    "            inputs1, labels1 = data1[0].to(device), data1[1].to(device)\n",
    "            outputs1 = model_invariant(inputs1, dataset_id=1).squeeze()\n",
    "            loss1 = model_invariant.module.loss(outputs1, labels1) if isinstance(model_invariant, DataParallel) else model_invariant.loss(outputs1, labels1)\n",
    "            penalty1 = penalty(outputs1, labels1, device)\n",
    "            \n",
    "            inputs2, labels2 = data2[0].to(device), data2[1].to(device)\n",
    "            outputs2 = model_invariant(inputs2, dataset_id=2).squeeze()\n",
    "            loss2 = model_invariant.module.loss(outputs2, labels2) if isinstance(model_invariant, DataParallel) else model_invariant.loss(outputs2, labels2)\n",
    "            penalty2 = penalty(outputs2, labels2, device)\n",
    "        \n",
    "            optimizer_invariant.zero_grad()        \n",
    "            # (loss1 + loss2).backward()            \n",
    "            (loss1 + penalty1 + loss2 + penalty2).backward()\n",
    "            optimizer_invariant.step()\n",
    "            \n",
    "            total_loss += (loss1.item() + loss2.item())\n",
    "            \n",
    "        if epoch%1==0:\n",
    "            with open(curdir + 'v2_script_10/logger_' + exp_name + '.log', 'a+') as file1:\n",
    "                file1.writelines(f'epoch: {epoch}, total_loss: {total_loss:.6f}\\n\\n')\n",
    "            \n",
    "        \n",
    "    return model_invariant.module\n",
    "\n",
    "## cathub, imr, (MAE, r2)\n",
    "## ocp, imr, (MAE, r2)\n",
    "df1 = pd.read_pickle(f'{curdir}datasets/df_cathub_dpp_combined.pickle')\n",
    "X1 = df1.iloc[:, :-1].values\n",
    "y1 = df1['nre'].values\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=ratio_test, random_state=seed)\n",
    "df2 = pd.read_pickle(f'{curdir}datasets/df_ocp_dpp_combined.pickle')\n",
    "X2 = df2.iloc[:, :-1].values\n",
    "y2 = df2['energy'].values\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=ratio_test, random_state=seed)\n",
    "print(X_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape)\n",
    "print(X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)\n",
    "\n",
    "train_data1 = TensorDataset(torch.tensor(X_train1, dtype=torch.float32), torch.tensor(y_train1, dtype=torch.float32))\n",
    "train_data2 = TensorDataset(torch.tensor(X_train2, dtype=torch.float32), torch.tensor(y_train2, dtype=torch.float32))\n",
    "\n",
    "batch_size = 10000\n",
    "train_loader1 = DataLoader(train_data1, batch_size=batch_size, shuffle=True)\n",
    "train_loader2 = DataLoader(train_data2, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "len(train_loader1), len(train_loader2)\n",
    "\n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_' + exp_name + '.pt'\n",
    "model_invariant = get_model_invariant(\n",
    "    train_loader1, train_loader2, \n",
    "    len_embedding, abstract_len_embedding\n",
    ")\n",
    "torch.save(model_invariant.state_dict(), model_path)\n",
    "\n",
    "## evaluation\n",
    "\n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_' + exp_name + '.pt'\n",
    "model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "model_invariant.load_state_dict(torch.load(model_path))\n",
    "model_invariant.eval()\n",
    "\n",
    "X_train_invariant1 = model_invariant.encoder(torch.tensor(X_train1, dtype=torch.float32)).detach().numpy()\n",
    "X_test_invariant1 = model_invariant.encoder(torch.tensor(X_test1, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "lr = 0.2\n",
    "depth = 8\n",
    "n_est = 500\n",
    "model1 = xgb.XGBRegressor(learning_rate=lr, max_depth=depth, n_estimators=n_est)\n",
    "model1.fit(X_train_invariant1, y_train1)\n",
    "\n",
    "y_pred1 = model1.predict(X_test_invariant1)\n",
    "mae1 = mean_absolute_error(y_test1, y_pred1)\n",
    "r2score1 = r2_score(y_test1, y_pred1)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(y_test1, y_pred1, alpha=0.5)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title(f'(cathub, invariant)')\n",
    "plt.plot([y_test1.min(), y_test1.max()], [y_test1.min(), y_test1.max()], 'k--', lw=2)\n",
    "plt.show()\n",
    "print()\n",
    "print(f'X_train shape: {X_train1.shape}, X_test shape: {X_test1.shape}')\n",
    "print(f'y_train shape: {y_train1.shape}, y_test shape: {y_test1.shape}')\n",
    "print(f'train to test ratio: {1-ratio_test}:{ratio_test}')\n",
    "print(f'Mean Abs. Error: {mae1:.2f}')\n",
    "print(f'R2-score: {r2score1:.2f}')\n",
    "\n",
    "X_train_invariant2 = model_invariant.encoder(torch.tensor(X_train2, dtype=torch.float32)).detach().numpy()\n",
    "X_test_invariant2 = model_invariant.encoder(torch.tensor(X_test2, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "lr = 0.2\n",
    "depth = 8\n",
    "n_est = 500\n",
    "model2 = xgb.XGBRegressor(learning_rate=lr, max_depth=depth, n_estimators=n_est)\n",
    "model2.fit(X_train_invariant2, y_train2)\n",
    "\n",
    "y_pred2 = model2.predict(X_test_invariant2)\n",
    "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
    "r2score2 = r2_score(y_test2, y_pred2)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(y_test2, y_pred2, alpha=0.5)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title(f'(cathub, invariant)')\n",
    "plt.plot([y_test2.min(), y_test2.max()], [y_test2.min(), y_test2.max()], 'k--', lw=2)\n",
    "plt.show()\n",
    "print()\n",
    "print(f'X_train shape: {X_train2.shape}, X_test shape: {X_test2.shape}')\n",
    "print(f'y_train shape: {y_train2.shape}, y_test shape: {y_test2.shape}')\n",
    "print(f'train to test ratio: {1-ratio_test}:{ratio_test}')\n",
    "print(f'Mean Abs. Error: {mae2:.2f}')\n",
    "print(f'R2-score: {r2score2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c26fc1-53a4-42e4-8535-e7913da4dc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499558cf-62de-4ff4-b160-49e045e37150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba884d68-d037-4053-8c50-d2542c635b88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c824e12-7b66-47d6-a006-b66c0f42f49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042acf24-cd63-4192-9694-743d8759ded2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56fa92-242e-4cb5-824a-1b73cf7b5b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69d3d0f-1413-4e34-854a-6e268f2ccdc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a19a2-206c-4012-a988-13f7560817da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c630ca-ef6c-485f-b8c5-d2380d5512b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## comment\n",
    "\n",
    "# explore the data from OCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a0b239-94f5-45e8-b13e-1773924449b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 20:48:07,874\tINFO util.py:159 -- Outdated packages:\n",
      "  ipywidgets==7.6.5 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "## import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import ray\n",
    "from itertools import combinations\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "import gc\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb25a34-1aca-4e45-8d92-0c9a15b31466",
   "metadata": {},
   "outputs": [],
   "source": [
    "## variables \n",
    "\n",
    "curdir = ''\n",
    "logging.basicConfig(\n",
    "    filename=curdir + 'logger.log', \n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "trial_no = 0\n",
    "seed = 42 + trial_no\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be4902f-4084-4811-b4ec-a50563561b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "## ocp\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d640986-d2fb-4025-8709-4688a5c75f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ocp1 = pd.read_parquet(curdir + 'datasets/ocp_reactions_info_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c309d7a3-127a-4563-902b-b636ebab0816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bulk_id</th>\n",
       "      <th>ads_id</th>\n",
       "      <th>bulk_mpid</th>\n",
       "      <th>bulk_symbols</th>\n",
       "      <th>ads_symbols</th>\n",
       "      <th>miller_index</th>\n",
       "      <th>shift</th>\n",
       "      <th>top</th>\n",
       "      <th>adsorption_site</th>\n",
       "      <th>class</th>\n",
       "      <th>...</th>\n",
       "      <th>p758</th>\n",
       "      <th>p759</th>\n",
       "      <th>p760</th>\n",
       "      <th>p761</th>\n",
       "      <th>p762</th>\n",
       "      <th>p763</th>\n",
       "      <th>p764</th>\n",
       "      <th>p765</th>\n",
       "      <th>p766</th>\n",
       "      <th>p767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2085</td>\n",
       "      <td>29</td>\n",
       "      <td>mp-976273</td>\n",
       "      <td>Hf6Ge4</td>\n",
       "      <td>*COCH2O</td>\n",
       "      <td>[2, 1, 0]</td>\n",
       "      <td>0.022</td>\n",
       "      <td>True</td>\n",
       "      <td>[[9.3, 4.58, 26.89]]</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.698056</td>\n",
       "      <td>0.273536</td>\n",
       "      <td>0.742442</td>\n",
       "      <td>0.618160</td>\n",
       "      <td>0.486411</td>\n",
       "      <td>-0.934350</td>\n",
       "      <td>0.204278</td>\n",
       "      <td>0.679431</td>\n",
       "      <td>0.341144</td>\n",
       "      <td>-0.852883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10724</td>\n",
       "      <td>20</td>\n",
       "      <td>mp-1247259</td>\n",
       "      <td>Ca6Rh2N6</td>\n",
       "      <td>*CHCO</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0.312</td>\n",
       "      <td>True</td>\n",
       "      <td>[[10.54, 1.25, 22.82]]</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.625508</td>\n",
       "      <td>-0.456795</td>\n",
       "      <td>0.304594</td>\n",
       "      <td>1.134157</td>\n",
       "      <td>-0.394405</td>\n",
       "      <td>-1.171003</td>\n",
       "      <td>-0.648138</td>\n",
       "      <td>-0.021550</td>\n",
       "      <td>-1.443121</td>\n",
       "      <td>0.004959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 793 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bulk_id  ads_id   bulk_mpid bulk_symbols ads_symbols miller_index  shift  \\\n",
       "0     2085      29   mp-976273       Hf6Ge4     *COCH2O    [2, 1, 0]  0.022   \n",
       "1    10724      20  mp-1247259     Ca6Rh2N6       *CHCO    [1, 0, 0]  0.312   \n",
       "\n",
       "    top         adsorption_site  class  ...      p758      p759      p760  \\\n",
       "0  True    [[9.3, 4.58, 26.89]]      1  ... -0.698056  0.273536  0.742442   \n",
       "1  True  [[10.54, 1.25, 22.82]]      2  ... -0.625508 -0.456795  0.304594   \n",
       "\n",
       "       p761      p762      p763      p764      p765      p766      p767  \n",
       "0  0.618160  0.486411 -0.934350  0.204278  0.679431  0.341144 -0.852883  \n",
       "1  1.134157 -0.394405 -1.171003 -0.648138 -0.021550 -1.443121  0.004959  \n",
       "\n",
       "[2 rows x 793 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ocp1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ed8ff5-0acb-49d2-ab5c-a92442b61b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(x):\n",
    "    try:\n",
    "        return str(''.join(map(str, x)))\n",
    "    except ValueError:\n",
    "        print(f\"Error with value: {x}\")\n",
    "        logging.info(f\"Error with value: {x}\")\n",
    "        return x\n",
    "\n",
    "df_ocp1.rename(columns={'energy': 'nre'}, inplace=True)\n",
    "df_ocp1['miller_index'] = df_ocp1['miller_index'].apply(convert_to_int)\n",
    "list_scols = ['s' + str(i) for i in range(9)]\n",
    "list_pcols = ['p' + str(i) for i in range(768)]\n",
    "list_cols = ['anomaly', 'bulk_mpid', 'miller_index'] + list_scols + list_pcols + ['nre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1a84a20-443f-427b-9fd1-2089b1179b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pkey = sorted(list(df_ocp1['pkey'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef97b35-5240-499b-897f-625a677b847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_pkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec6ad742-78ea-4f88-a532-71b308f24cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ocp1 = df_ocp1[list_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe3d4f88-7700-44dd-b415-1c9e41fd8dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(437781, 781)\n"
     ]
    }
   ],
   "source": [
    "print(df_ocp1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4f7cd61-c3a1-4c68-b198-5fe38d891852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['anomaly', 'bulk_mpid', 'miller_index', 's0', 's1', 's2', 's3', 's4',\n",
      "       's5', 's6',\n",
      "       ...\n",
      "       'p759', 'p760', 'p761', 'p762', 'p763', 'p764', 'p765', 'p766', 'p767',\n",
      "       'nre'],\n",
      "      dtype='object', length=781)\n"
     ]
    }
   ],
   "source": [
    "print(df_ocp1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10bdf01b-f652-440b-9492-f8c93cb59c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce8adc86-a459-41df-adb1-6c757ba92cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'case_1': 325743, 'case_2': 402184, 'case_3': 418753, 'case_4': 433989, 'case_5': 437781}\n"
     ]
    }
   ],
   "source": [
    "cases = {\n",
    "    'case_1': [0],\n",
    "    'case_2': [0,1],\n",
    "    'case_3': [0,1,2],\n",
    "    'case_4': [0,1,2,3],\n",
    "    'case_5': df_ocp1['anomaly'].unique()\n",
    "}\n",
    "sample_counts = {}\n",
    "filtered_dfs = {}\n",
    "for case, values in cases.items():\n",
    "    filtered_df = df_ocp1[df_ocp1['anomaly'].isin(values)]\n",
    "    filtered_dfs[case] = filtered_df\n",
    "    sample_counts[case] = len(filtered_df)\n",
    "print(sample_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bfeedbf-e72f-457a-b434-7a6634fd7384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4096926886057743 2.043792159537874\n",
      "-1.600708582462779 2.270462035025037\n",
      "-1.587948442131603 2.2734108175746686\n",
      "-1.5810491737774808 2.2811852803293022\n",
      "-1.5607516413861389 2.2868426774779977\n",
      "{'case_1': 226270, 'case_2': 287317, 'case_3': 301206, 'case_4': 311997, 'case_5': 313744}\n"
     ]
    }
   ],
   "source": [
    "cases = {\n",
    "    'case_1': [0],\n",
    "    'case_2': [0,1],\n",
    "    'case_3': [0,1,2],\n",
    "    'case_4': [0,1,2,3],\n",
    "    'case_5': df_ocp1['anomaly'].unique()\n",
    "}\n",
    "\n",
    "sample_counts = {}\n",
    "filtered_dfs = {}\n",
    "for case, values in cases.items():\n",
    "    filtered_df = df_ocp1[df_ocp1['anomaly'].isin(values)]\n",
    "    \n",
    "    # Assuming 'anomaly' column contains the values for which you want to detect outliers\n",
    "    mean_val = filtered_df['nre'].mean()\n",
    "    std_val = filtered_df['nre'].std()\n",
    "\n",
    "    # Filter rows\n",
    "    print(mean_val, std_val)\n",
    "    no_outliers_df = filtered_df[\n",
    "        (filtered_df['nre'] >= mean_val - 1*std_val) &\n",
    "        (filtered_df['nre'] <= mean_val + 1*std_val)\n",
    "    ]\n",
    "    \n",
    "    filtered_dfs[case] = no_outliers_df\n",
    "    sample_counts[case] = len(no_outliers_df)\n",
    "\n",
    "print(sample_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dea6354-14e5-4801-b5a9-08493c27b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Preprocess Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b99eac-34d5-43da-ba11-87a1bc58d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess data\n",
    "def preprocess_data(train, test, use_pca=False):\n",
    "    features = list(train.columns[3:-1])  # s0 to p767\n",
    "    X_train = train[features]\n",
    "    X_test = test[features]\n",
    "    y_train = train['nre']\n",
    "    y_test = test['nre']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    # X_train_scaled = scaler.fit_transform(X_train)\n",
    "    # X_test_scaled = scaler.transform(X_test)\n",
    "    X_train_scaled = X_train\n",
    "    X_test_scaled = X_test    \n",
    "\n",
    "    if use_pca:\n",
    "        pca = PCA(0.9)\n",
    "        X_train_scaled = pca.fit_transform(X_train_scaled)\n",
    "        X_test_scaled = pca.transform(X_test_scaled)\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56d02430-1daa-46bb-bc54-fdc788266476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Splitting based on groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e326aa74-8b2f-4550-a2af-5f6cd71b6fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case: case_1\n",
      "Shape: (169769, 781), (56501, 781)\n",
      "Total groups: 72315\n",
      "Training groups: 54236\n",
      "Testing groups: 18079\n",
      "\n",
      "Case: case_2\n",
      "Shape: (215958, 781), (71359, 781)\n",
      "Total groups: 78336\n",
      "Training groups: 58752\n",
      "Testing groups: 19584\n",
      "\n",
      "Case: case_3\n",
      "Shape: (227129, 781), (74077, 781)\n",
      "Total groups: 79694\n",
      "Training groups: 59770\n",
      "Testing groups: 19924\n",
      "\n",
      "Case: case_4\n",
      "Shape: (234094, 781), (77903, 781)\n",
      "Total groups: 82254\n",
      "Training groups: 61690\n",
      "Testing groups: 20564\n",
      "\n",
      "Case: case_5\n",
      "Shape: (236002, 781), (77742, 781)\n",
      "Total groups: 82383\n",
      "Training groups: 61787\n",
      "Testing groups: 20596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a function to split based on groups\n",
    "def split_data(df, group_columns):\n",
    "    gss = GroupShuffleSplit(n_splits=1, train_size=0.75, random_state=seed)\n",
    "    for train_idx, test_idx in gss.split(df, groups=df[group_columns].astype(str).apply(lambda x: '_'.join(x), axis=1)):\n",
    "        train = df.iloc[train_idx]\n",
    "        test = df.iloc[test_idx]\n",
    "    return train, test\n",
    "\n",
    "train_test_splits = {}\n",
    "for case, filtered_df in filtered_dfs.items():\n",
    "    train, test = split_data(filtered_df, ['bulk_mpid', 'miller_index'])\n",
    "    train_test_splits[case] = (train, test)\n",
    "    \n",
    "    # Calculate unique groups for total, train, and test datasets\n",
    "    total_groups = filtered_df[['bulk_mpid', 'miller_index']].drop_duplicates().shape[0]\n",
    "    train_groups = train[['bulk_mpid', 'miller_index']].drop_duplicates().shape[0]\n",
    "    test_groups = test[['bulk_mpid', 'miller_index']].drop_duplicates().shape[0]\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Case: {case}\")\n",
    "    print(f\"Shape: {train.shape}, {test.shape}\")    \n",
    "    print(f\"Total groups: {total_groups}\")\n",
    "    print(f\"Training groups: {train_groups}\")\n",
    "    print(f\"Testing groups: {test_groups}\\n\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50981e3b-403e-429c-bd17-5c2f3d4b4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37e13bb3-2cf3-4c20-8bb6-0668498a6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c614c2f-3e53-459b-8c9f-f3e1d7d46627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models & hyperparameters\n",
    "models = {\n",
    "    'Ridge Regression': {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'alpha': [1.0],\n",
    "        }\n",
    "    },\n",
    "    'Elastic Regression': {\n",
    "        'model': ElasticNet(),\n",
    "        'params': {\n",
    "            'alpha': [1.0],\n",
    "            'l1_ratio': [0.5]\n",
    "        }\n",
    "    },\n",
    "    # 'Kernel Ridge Regression': {\n",
    "    #     'model': KernelRidge(),\n",
    "    #     'params': {\n",
    "    #         'alpha': [1],\n",
    "    #         'kernel': ['linear'],\n",
    "    #         'degree': [3]\n",
    "    #     }\n",
    "    # },\n",
    "    # 'Support Vector Regression': {\n",
    "    #     'model': SVR(),\n",
    "    #     'params': {\n",
    "    #         'C': [1.0],\n",
    "    #         'kernel': ['rbf'],\n",
    "    #         'gamma': ['scale']\n",
    "    #     }\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40b3d59-2e69-4bed-87f1-ba71fd24c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot and save the figures\n",
    "def plot_and_save(predicted, true, case, model_name, transformation, folder='outputs'):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.scatter(true, predicted, alpha=0.5)\n",
    "    plt.xlabel('True')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(f\"{case}: {model_name} ({transformation})\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the figure\n",
    "    # Ensure the 'outputs' directory exists\n",
    "    if not os.path.exists(curdir + folder):\n",
    "        os.makedirs(curdir + folder)\n",
    "    \n",
    "    plt.savefig(f\"{curdir}{folder}/{case}D_{model_name}_{transformation}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f540aa12-f490-4215-9fd2-52f2c2546be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case: case_1\n",
      "(169769, 777) (56501, 777) (169769,) (56501,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "(169769, 2) (56501, 2) (169769,) (56501,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "case: case_2\n",
      "(215958, 777) (71359, 777) (215958,) (71359,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "(215958, 2) (71359, 2) (215958,) (71359,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "case: case_3\n",
      "(227129, 777) (74077, 777) (227129,) (74077,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "(227129, 2) (74077, 2) (227129,) (74077,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "case: case_4\n",
      "(234094, 777) (77903, 777) (234094,) (77903,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "(234094, 2) (77903, 2) (234094,) (77903,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "case: case_5\n",
      "(236002, 777) (77742, 777) (236002,) (77742,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n",
      "(236002, 2) (77742, 2) (236002,) (77742,)\n",
      "Ridge Regression\n",
      "Elastic Regression\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "selected_cases = ['case_1', 'case_2', 'case_3', 'case_4', 'case_5'] \n",
    "for case, (train, test) in train_test_splits.items():\n",
    "    if case not in selected_cases:  # Skip the cases not in selected_cases\n",
    "        continue    \n",
    "    print(f\"case: {case}\")\n",
    "    \n",
    "    #############################################################################################################################\n",
    "    X_train, X_test, y_train, y_test = preprocess_data(train, test, use_pca=False) # For non-PCA version\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    for model_name, model_details in models.items():\n",
    "        print(model_name)\n",
    "        clf = GridSearchCV(model_details['model'], model_details['params'], cv=5, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "        clf.fit(X_train, y_train)    \n",
    "        predicted = clf.predict(X_test)\n",
    "        mae = -clf.score(X_test, y_test)\n",
    "        params = clf.best_params_\n",
    "        mean_target = y_test.abs().mean()\n",
    "        # Store the results\n",
    "        results[(case, model_name, 'non_pca')] = (mae, mean_target, params)\n",
    "        \n",
    "        # Plot\n",
    "        plot_and_save(predicted, y_test, case, model_name, 'non_pca')\n",
    "        del predicted\n",
    "    del X_train, X_test, y_train, y_test\n",
    "    gc.collect()\n",
    "    \n",
    "    #############################################################################################################################        \n",
    "    X_train, X_test, y_train, y_test = preprocess_data(train, test, use_pca=True) # For PCA version\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)    \n",
    "    for model_name, model_details in models.items():\n",
    "        print(model_name)\n",
    "        clf = GridSearchCV(model_details['model'], model_details['params'], cv=5, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        predicted = clf.predict(X_test)\n",
    "        mae = -clf.score(X_test, y_test)\n",
    "        params = clf.best_params_\n",
    "        mean_target = y_test.abs().mean()\n",
    "        # Store the results\n",
    "        results[(case, model_name, 'pca')] = (mae, mean_target, params)\n",
    "        \n",
    "        # Plot\n",
    "        plot_and_save(predicted, y_test, case, model_name, 'pca')\n",
    "        del predicted\n",
    "        \n",
    "    del X_train, X_test, y_train, y_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e76602ed-b161-4519-902f-426955183a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('case_1', 'Elastic Regression', 'non_pca'): (0.9072895029024735,\n",
      "                                               1.6065797755235314,\n",
      "                                               {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_1', 'Elastic Regression', 'pca'): (0.9072186601769682,\n",
      "                                           1.6065797755235314,\n",
      "                                           {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_1', 'Ridge Regression', 'non_pca'): (2.5736615343264986,\n",
      "                                             1.6065797755235314,\n",
      "                                             {'alpha': 1.0}),\n",
      " ('case_1', 'Ridge Regression', 'pca'): (0.9072186601769682,\n",
      "                                         1.6065797755235314,\n",
      "                                         {'alpha': 1.0}),\n",
      " ('case_2', 'Elastic Regression', 'non_pca'): (1.0023311206008942,\n",
      "                                               1.781291733359914,\n",
      "                                               {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_2', 'Elastic Regression', 'pca'): (1.0023237755450198,\n",
      "                                           1.781291733359914,\n",
      "                                           {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_2', 'Ridge Regression', 'non_pca'): (0.8017338244131234,\n",
      "                                             1.781291733359914,\n",
      "                                             {'alpha': 1.0}),\n",
      " ('case_2', 'Ridge Regression', 'pca'): (1.0023237755450198,\n",
      "                                         1.781291733359914,\n",
      "                                         {'alpha': 1.0}),\n",
      " ('case_3', 'Elastic Regression', 'non_pca'): (1.006605824731435,\n",
      "                                               1.7828175511790445,\n",
      "                                               {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_3', 'Elastic Regression', 'pca'): (1.0066182152662175,\n",
      "                                           1.7828175511790445,\n",
      "                                           {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_3', 'Ridge Regression', 'non_pca'): (0.7827307118253992,\n",
      "                                             1.7828175511790445,\n",
      "                                             {'alpha': 1.0}),\n",
      " ('case_3', 'Ridge Regression', 'pca'): (1.0066182152662175,\n",
      "                                         1.7828175511790445,\n",
      "                                         {'alpha': 1.0}),\n",
      " ('case_4', 'Elastic Regression', 'non_pca'): (1.0157105724490514,\n",
      "                                               1.775664547023928,\n",
      "                                               {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_4', 'Elastic Regression', 'pca'): (1.0068197351334196,\n",
      "                                           1.775664547023928,\n",
      "                                           {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_4', 'Ridge Regression', 'non_pca'): (1500.8307462990358,\n",
      "                                             1.775664547023928,\n",
      "                                             {'alpha': 1.0}),\n",
      " ('case_4', 'Ridge Regression', 'pca'): (1.0068197351334196,\n",
      "                                         1.775664547023928,\n",
      "                                         {'alpha': 1.0}),\n",
      " ('case_5', 'Elastic Regression', 'non_pca'): (216.55352598834102,\n",
      "                                               1.774622557659246,\n",
      "                                               {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_5', 'Elastic Regression', 'pca'): (1.0089485825108215,\n",
      "                                           1.774622557659246,\n",
      "                                           {'alpha': 1.0, 'l1_ratio': 0.5}),\n",
      " ('case_5', 'Ridge Regression', 'non_pca'): (1444.5464855103119,\n",
      "                                             1.774622557659246,\n",
      "                                             {'alpha': 1.0}),\n",
      " ('case_5', 'Ridge Regression', 'pca'): (1.0089485825108215,\n",
      "                                         1.774622557659246,\n",
      "                                         {'alpha': 1.0})}\n"
     ]
    }
   ],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea901530-baf6-4dba-bad8-e4eea87c1199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ac8f0-73be-4ffe-9c8b-eca672e3c842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aafda73-39bd-4bc6-8867-624af606261b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

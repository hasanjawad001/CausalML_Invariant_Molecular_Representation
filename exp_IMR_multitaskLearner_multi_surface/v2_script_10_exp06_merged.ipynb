{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cda9aa7-2559-4e34-887e-44c79ec7419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## install\n",
    "# !pip install xgboost\n",
    "\n",
    "## import\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "## variables\n",
    "seed = 42\n",
    "ratio_test = 0.2\n",
    "n_sample_imr, exp_name = 2000, 'exp6' ## imr (pca_components) length 1024, siamese model structure changed\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "## class\n",
    "class SiameseNetwork(torch.nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.nn_reg = nn.Sequential(\n",
    "            ## 1024 to 2048\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*2)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*2)), \n",
    "            ## 2048 to 1536\n",
    "            nn.Linear(int(self.len_embedding*2), int(self.len_embedding*1.5)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*1.5)),\n",
    "            ## 1526 to 1048\n",
    "            nn.Linear(int(self.len_embedding*1.5), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.nn_final_reg = nn.Sequential(\n",
    "            ##  (1024+1024) to 1\n",
    "            nn.Linear(self.abstract_len_embedding * 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward_reg(self, x):\n",
    "        output = self.nn_reg(x)\n",
    "        return output\n",
    "\n",
    "    def forward_final_reg(self, x):\n",
    "        output = self.nn_final_reg(x)\n",
    "        return output\n",
    "\n",
    "    def forward(self, fp1, fp2):\n",
    "        a = self.forward_reg(fp1)\n",
    "        b = self.forward_reg(fp2)\n",
    "        x = torch.cat([a, b], dim=1)  # hstack\n",
    "        output = self.forward_final_reg(x)\n",
    "        return output\n",
    "\n",
    "## function\n",
    "\n",
    "def get_secondary_env(env):\n",
    "    x_e, y_e = env[0], env[1]\n",
    "    print(x_e.shape, y_e.shape)\n",
    "    list_secondary_feature, list_secondary_target = [], []\n",
    "    for i in range(x_e.shape[0]):\n",
    "        for j in range(x_e.shape[0]):\n",
    "            if i != j:\n",
    "                sf = np.hstack((x_e[i], x_e[j]))\n",
    "                st = y_e[i] - y_e[j]\n",
    "                list_secondary_feature.append(sf)\n",
    "                list_secondary_target.append(st)\n",
    "    array_secondary_feature = np.array(list_secondary_feature, dtype='float32')\n",
    "    array_secondary_target = np.array(list_secondary_target, dtype='float32').reshape((-1, 1))\n",
    "    senv = torch.from_numpy(array_secondary_feature), torch.from_numpy(array_secondary_target)\n",
    "    print(senv[0].shape, senv[1].shape)\n",
    "    return senv\n",
    "\n",
    "\n",
    "def get_model_siamese(senvironments, len_embedding, abstract_len_embedding, batch_size=10000):\n",
    "    print(f'len_embedding: {len_embedding}, abstract_len_embedding: {abstract_len_embedding}')\n",
    "\n",
    "    _lr, num_iterations = 1e-3, 1000\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n",
    "    model_siamese = SiameseNetwork(len_embedding, abstract_len_embedding).to(device)\n",
    "    optimizer_siamese = torch.optim.Adam(model_siamese.parameters(), lr=_lr)\n",
    "\n",
    "    for epoch in range(num_iterations):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        for x, y in senvironments:\n",
    "            p = torch.randperm(len(x))\n",
    "            x, y = x[p], y[p]\n",
    "            \n",
    "            for i in range(0, len(x), batch_size):\n",
    "                batch_x = x[i:i+batch_size].to(device)\n",
    "                batch_y = y[i:i+batch_size].to(device)\n",
    "                ##\n",
    "                fp1 = batch_x[:, list(range(0, len_embedding, 1))]\n",
    "                fp2 = batch_x[:, list(range(len_embedding, 2 * len_embedding, 1))]\n",
    "                ##\n",
    "                y_pred_siamese = model_siamese(fp1, fp2)\n",
    "                batch_loss = model_siamese.loss(y_pred_siamese, batch_y)\n",
    "                ##\n",
    "                optimizer_siamese.zero_grad()  # Clear buffer\n",
    "                batch_loss.backward()  # Calculate gradient for all params\n",
    "                optimizer_siamese.step()  # Update parameters\n",
    "                ## \n",
    "                epoch_loss += float(batch_loss.item())\n",
    "                \n",
    "        if epoch % (int(num_iterations // 10)) == 0:\n",
    "            with open('/curdir/v2_script_10/logger_' + exp_name + '.log', 'a+') as file1:\n",
    "                file1.writelines(f'epoch: {epoch}, total_loss: {epoch_loss:.6f}\\n\\n')\n",
    "\n",
    "    return model_siamese\n",
    "\n",
    "\n",
    "## check for word ('cathub/ocp', 'nre/energy', 'original/pca')\n",
    "## common (dimenet++, Two-Functional-Model, xgboost) \n",
    "## (cathub/ocp x org/pca/imr x MAE/r2) \n",
    "\n",
    "## 5. cathub, imr, (MAE, r2)\n",
    "## 6. ocp, imr, (MAE, r2)\n",
    "\n",
    "df1 = pd.read_pickle(f'/curdir/datasets/df_cathub_dpp_combined.pickle')\n",
    "X1 = df1.iloc[:, :-1].values\n",
    "y1 = df1['nre'].values\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=ratio_test, random_state=seed)\n",
    "df2 = pd.read_pickle(f'/curdir/datasets/df_ocp_dpp_combined.pickle')\n",
    "X2 = df2.iloc[:, :-1].values\n",
    "y2 = df2['energy'].values\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=ratio_test, random_state=seed)\n",
    "print(X_train1.shape, X_test1.shape, y_train1.shape, y_test1.shape)\n",
    "print(X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape)\n",
    "\n",
    "## choose 'n' samples from cathub\n",
    "## turn to 'n(n-1)' secondary by '2d'\n",
    "idx1 = np.random.choice(X_train1.shape[0], n_sample_imr, replace=False)\n",
    "X_train1_sampled = X_train1[idx1]\n",
    "y_train1_sampled = y_train1[idx1]\n",
    "env1 = (X_train1_sampled, y_train1_sampled)\n",
    "senv1 = get_secondary_env(env1)\n",
    "## choose 'n' samples from ocp\n",
    "## turn to 'n(n-1)' secondary by '2d'\n",
    "idx2 = np.random.choice(X_train2.shape[0], n_sample_imr, replace=False)\n",
    "X_train2_sampled = X_train2[idx2]\n",
    "y_train2_sampled = y_train2[idx2]\n",
    "env2 = (X_train2_sampled, y_train2_sampled)\n",
    "senv2 = get_secondary_env(env2)\n",
    "## build a SiameseIMR to transform 'd' to 'pca(d)',\n",
    "## use that 'SiameseIMR transformation' instead of pca\n",
    "senvironments = [senv1, senv2]\n",
    "pca_components = int(int(X_train1.shape[1])//1)\n",
    "len_embedding, abstract_len_embedding = int(senvironments[0][0].shape[1])//2, pca_components    \n",
    "model_siamese = get_model_siamese(\n",
    "    senvironments, \n",
    "    len_embedding, \n",
    "    abstract_len_embedding,    \n",
    ")\n",
    "## save the model\n",
    "model_path = '/curdir/v2_script_10/model_siamese_' + exp_name + '.pt'\n",
    "torch.save(model_siamese.state_dict(), model_path)\n",
    "\n",
    "# load the model\n",
    "model_siamese = SiameseNetwork(len_embedding, abstract_len_embedding)\n",
    "model_siamese.load_state_dict(torch.load(model_path))\n",
    "model_siamese.eval()\n",
    "\n",
    "X_train_siamese1 = model_siamese.forward_reg(torch.from_numpy(X_train1).float()).detach().numpy() \n",
    "X_test_siamese1 = model_siamese.forward_reg(torch.from_numpy(X_test1).float()).detach().numpy()\n",
    "\n",
    "lr = 0.2\n",
    "depth = 8\n",
    "n_est = 500\n",
    "model1 = xgb.XGBRegressor(learning_rate=lr, max_depth=depth, n_estimators=n_est)\n",
    "model1.fit(X_train_siamese1, y_train1)\n",
    "\n",
    "y_pred1 = model1.predict(X_test_siamese1)\n",
    "mae1 = mean_absolute_error(y_test1, y_pred1)\n",
    "r2score1 = r2_score(y_test1, y_pred1)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(y_test1, y_pred1, alpha=0.5)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title(f'(cathub, siamese)')\n",
    "plt.plot([y_test1.min(), y_test1.max()], [y_test1.min(), y_test1.max()], 'k--', lw=2)\n",
    "plt.show()\n",
    "print(f'X_train shape: {X_train1.shape}, X_test shape: {X_test1.shape}')\n",
    "print(f'y_train shape: {y_train1.shape}, y_test shape: {y_test1.shape}')\n",
    "print(f'train to test ratio: {1-ratio_test}:{ratio_test}')\n",
    "print(f'Mean Abs. Error: {mae1:.2f}')\n",
    "print(f'R2-score: {r2score1:.2f}')\n",
    "\n",
    "X_train_siamese2 = model_siamese.forward_reg(torch.from_numpy(X_train2).float()).detach().numpy() \n",
    "X_test_siamese2 = model_siamese.forward_reg(torch.from_numpy(X_test2).float()).detach().numpy()\n",
    "\n",
    "lr = 0.2\n",
    "depth = 8\n",
    "n_est = 500\n",
    "model2 = xgb.XGBRegressor(learning_rate=lr, max_depth=depth, n_estimators=n_est)\n",
    "model2.fit(X_train_siamese2, y_train2)\n",
    "\n",
    "y_pred2 = model2.predict(X_test_siamese2)\n",
    "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
    "r2score2 = r2_score(y_test2, y_pred2)\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.scatter(y_test2, y_pred2, alpha=0.5)\n",
    "plt.xlabel('y_test')\n",
    "plt.ylabel('y_pred')\n",
    "plt.title(f'(ocp, siamese)')\n",
    "plt.plot([y_test2.min(), y_test2.max()], [y_test2.min(), y_test2.max()], 'k--', lw=2)\n",
    "plt.show()\n",
    "print(f'X_train shape: {X_train2.shape}, X_test shape: {X_test2.shape}')\n",
    "print(f'y_train shape: {y_train2.shape}, y_test shape: {y_test2.shape}')\n",
    "print(f'train to test ratio: {1-ratio_test}:{ratio_test}')\n",
    "print(f'Mean Abs. Error: {mae2:.2f}')\n",
    "print(f'R2-score: {r2score2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc332d09-f7a4-485c-8b3c-3745032d6991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a61b4f-0cd0-4178-a238-e86e6bc9c965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20b25b-b35e-447b-9d43-0a8fc40b1b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1705f-7e6f-40a9-b1ae-533e13329faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134b50f-d2be-41a2-9d69-85776e77acb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

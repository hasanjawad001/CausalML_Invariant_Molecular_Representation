{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a91ca3-65ac-4797-ae19-5add12ac8bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train:test = 80:20, trials = 10</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Org(1024)</th>\n",
       "      <th>EncDec(256)</th>\n",
       "      <th>nonlinear head(256)</th>\n",
       "      <th>PCgrad(256)</th>\n",
       "      <th>IRM(1024)</th>\n",
       "      <th>PCgrad(1024)</th>\n",
       "      <th>nonlinear head + separate step(256)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset</td>\n",
       "      <td>functional</td>\n",
       "      <td>N_samples</td>\n",
       "      <td>org</td>\n",
       "      <td>pca</td>\n",
       "      <td>9f</td>\n",
       "      <td>12c</td>\n",
       "      <td>11b</td>\n",
       "      <td>11c</td>\n",
       "      <td>9g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AraComputational2022</td>\n",
       "      <td>PBE-D3</td>\n",
       "      <td>64</td>\n",
       "      <td>0.31 ± 0.56</td>\n",
       "      <td>-0.21 ± 0.92</td>\n",
       "      <td>-0.16 ± 1.05</td>\n",
       "      <td>-0.08 ± 0.74</td>\n",
       "      <td>-0.18 ± 1.45</td>\n",
       "      <td>-0.68 ± 0.76</td>\n",
       "      <td>-0.01 ± 0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BajdichWO32018</td>\n",
       "      <td>PBE+U</td>\n",
       "      <td>84</td>\n",
       "      <td>0.62 ± 0.16</td>\n",
       "      <td>0.41 ± 0.11</td>\n",
       "      <td>0.44 ± 0.18</td>\n",
       "      <td>0.43 ± 0.17</td>\n",
       "      <td>-0.35 ± 0.51</td>\n",
       "      <td>-0.53 ± 0.39</td>\n",
       "      <td>0.35 ± 0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BoesAdsorption2018</td>\n",
       "      <td>RPBE</td>\n",
       "      <td>49</td>\n",
       "      <td>0.51 ± 0.30</td>\n",
       "      <td>-0.63 ± 1.84</td>\n",
       "      <td>0.26 ± 0.79</td>\n",
       "      <td>0.39 ± 0.33</td>\n",
       "      <td>0.11 ± 0.89</td>\n",
       "      <td>0.25 ± 0.63</td>\n",
       "      <td>0.06 ± 1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ComerUnraveling2022</td>\n",
       "      <td>PBE+U</td>\n",
       "      <td>66</td>\n",
       "      <td>0.59 ± 0.43</td>\n",
       "      <td>0.17 ± 0.60</td>\n",
       "      <td>0.31 ± 0.49</td>\n",
       "      <td>0.18 ± 0.42</td>\n",
       "      <td>0.15 ± 0.77</td>\n",
       "      <td>0.53 ± 0.32</td>\n",
       "      <td>0.27 ± 0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HossainInvestigation2022</td>\n",
       "      <td>PBE+U</td>\n",
       "      <td>365</td>\n",
       "      <td>0.80 ± 0.03</td>\n",
       "      <td>0.60 ± 0.13</td>\n",
       "      <td>0.73 ± 0.07</td>\n",
       "      <td>0.55 ± 0.09</td>\n",
       "      <td>0.76 ± 0.06</td>\n",
       "      <td>0.41 ± 0.07</td>\n",
       "      <td>0.68 ± 0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train:test = 80:20, trials = 10  Unnamed: 1 Unnamed: 2    Org(1024)  \\\n",
       "0                             NaN         NaN        NaN          NaN   \n",
       "1                             NaN         NaN        NaN          NaN   \n",
       "2                             NaN         NaN        NaN          NaN   \n",
       "3                             NaN         NaN        NaN          NaN   \n",
       "4                         dataset  functional  N_samples          org   \n",
       "5            AraComputational2022      PBE-D3         64  0.31 ± 0.56   \n",
       "6                  BajdichWO32018       PBE+U         84  0.62 ± 0.16   \n",
       "7              BoesAdsorption2018        RPBE         49  0.51 ± 0.30   \n",
       "8             ComerUnraveling2022       PBE+U         66  0.59 ± 0.43   \n",
       "9        HossainInvestigation2022       PBE+U        365  0.80 ± 0.03   \n",
       "\n",
       "    EncDec(256) nonlinear head(256)   PCgrad(256)     IRM(1024)  PCgrad(1024)  \\\n",
       "0           NaN                 NaN           NaN           NaN           NaN   \n",
       "1           NaN                 NaN           NaN           NaN           NaN   \n",
       "2           NaN                 NaN           NaN           NaN           NaN   \n",
       "3           NaN                 NaN           NaN           NaN           NaN   \n",
       "4           pca                  9f           12c           11b           11c   \n",
       "5  -0.21 ± 0.92        -0.16 ± 1.05  -0.08 ± 0.74  -0.18 ± 1.45  -0.68 ± 0.76   \n",
       "6   0.41 ± 0.11         0.44 ± 0.18   0.43 ± 0.17  -0.35 ± 0.51  -0.53 ± 0.39   \n",
       "7  -0.63 ± 1.84         0.26 ± 0.79   0.39 ± 0.33   0.11 ± 0.89   0.25 ± 0.63   \n",
       "8   0.17 ± 0.60         0.31 ± 0.49   0.18 ± 0.42   0.15 ± 0.77   0.53 ± 0.32   \n",
       "9   0.60 ± 0.13         0.73 ± 0.07   0.55 ± 0.09   0.76 ± 0.06   0.41 ± 0.07   \n",
       "\n",
       "  nonlinear head + separate step(256)  \n",
       "0                                 NaN  \n",
       "1                                 NaN  \n",
       "2                                 NaN  \n",
       "3                                 NaN  \n",
       "4                                  9g  \n",
       "5                        -0.01 ± 0.42  \n",
       "6                         0.35 ± 0.34  \n",
       "7                         0.06 ± 1.63  \n",
       "8                         0.27 ± 0.37  \n",
       "9                         0.68 ± 0.09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('v2_script_10/exp12/20240417_eval.xlsx', sheet_name=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca808a06-9f3f-4b12-815e-b4f98c636dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412c8d7-7696-4693-a928-7efb168ebfa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443dc8a9-f8b9-4939-9bd1-340740faf42c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57b40fe0-7ac7-4854-8934-380469ac6583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.nn import DataParallel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import torch.autograd as autograd\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.optim as optim\n",
    "from torch.nn import DataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1dcb38a-ac2f-4b80-b718-edfeab234b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "ratio_test = 0.2\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "exp_name = 'exp_12c'\n",
    "curdir = '' ## '/curdir/' ## ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8475c09-a8e3-4a74-a818-fd06709913cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, len_emb=1024, abs_len_emb=256):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(len_emb, int(len_emb*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(len_emb*0.5)),\n",
    "            nn.Linear(int(len_emb*0.5), abs_len_emb)  # Bottleneck layer\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(abs_len_emb, int(len_emb*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(len_emb*0.5)),\n",
    "            nn.Linear(int(len_emb*0.5), len_emb),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction='mean')\n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.5)),\n",
    "\n",
    "            nn.Linear(int(self.len_embedding*0.5), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "\n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "483248c4-e1b3-479e-a842-23ee469e691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pid = [\n",
    "    'AraComputational2022',\n",
    "    'BajdichWO32018',\n",
    "    'BoesAdsorption2018',\n",
    "    'ComerUnraveling2022',\n",
    "    'HossainInvestigation2022',\n",
    "    'KoshyInvestigation2022',\n",
    "    'LiuCatalytic2022',\n",
    "    'RaoResolving2022',\n",
    "    'TettehCompressively2022',\n",
    "    'WeiInsights2022',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d4b7d-7c14-416f-8295-743f6099e254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30454d04-fb70-4b46-8d66-5f3a3973d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 569.558349609375\n",
      "Epoch 5001, Loss: 514.48681640625\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 569.2937622070312\n",
      "Epoch 5001, Loss: 514.2552490234375\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 568.9877319335938\n",
      "Epoch 5001, Loss: 513.875\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 569.1917724609375\n",
      "Epoch 5001, Loss: 514.1798706054688\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 569.4763793945312\n",
      "Epoch 5001, Loss: 514.4011840820312\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 569.8125610351562\n",
      "Epoch 5001, Loss: 514.8035278320312\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 568.6478881835938\n",
      "Epoch 5001, Loss: 513.5564575195312\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 569.3175048828125\n",
      "Epoch 5001, Loss: 514.2330932617188\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 569.3018188476562\n",
      "Epoch 5001, Loss: 514.2630615234375\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "Epoch 1, Loss: 569.704345703125\n",
      "Epoch 5001, Loss: 514.5322265625\n",
      "0.9172519720865738 0.1518753366006483\n",
      "0.30830291852826536 0.5617355837260728\n",
      "1.197701092479607 0.16115893051312608\n",
      "-0.21471987340736604 0.922397183478721\n",
      "1.1811897040278818 0.30738771517413005\n",
      "-0.07889972236296063 0.7374039892940758\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 712.2428588867188\n",
      "Epoch 5001, Loss: 655.7291870117188\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 713.31591796875\n",
      "Epoch 5001, Loss: 656.8037109375\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 712.2896118164062\n",
      "Epoch 5001, Loss: 655.8001098632812\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 713.399169921875\n",
      "Epoch 5001, Loss: 656.8991088867188\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 711.8490600585938\n",
      "Epoch 5001, Loss: 655.357421875\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 712.582763671875\n",
      "Epoch 5001, Loss: 656.0941162109375\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 713.6259155273438\n",
      "Epoch 5001, Loss: 657.1266479492188\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 712.6817626953125\n",
      "Epoch 5001, Loss: 656.1754760742188\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 712.9429931640625\n",
      "Epoch 5001, Loss: 656.4105834960938\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 713.0997924804688\n",
      "Epoch 5001, Loss: 656.5863037109375\n",
      "0.6604356938055409 0.1273462820380747\n",
      "0.6177013614060127 0.15705267249130023\n",
      "0.8354814536000397 0.09968109316333375\n",
      "0.4085994413237901 0.10922790742559076\n",
      "0.8551386723205392 0.154987068629383\n",
      "0.43030457825056445 0.16519773498456594\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 180.1912384033203\n",
      "Epoch 5001, Loss: 138.6609649658203\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 180.87290954589844\n",
      "Epoch 5001, Loss: 139.49729919433594\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 180.56922912597656\n",
      "Epoch 5001, Loss: 139.08653259277344\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 180.1543426513672\n",
      "Epoch 5001, Loss: 138.9822998046875\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 180.74539184570312\n",
      "Epoch 5001, Loss: 139.38375854492188\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 183.61097717285156\n",
      "Epoch 5001, Loss: 141.58343505859375\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 179.16688537597656\n",
      "Epoch 5001, Loss: 137.78067016601562\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 178.64535522460938\n",
      "Epoch 5001, Loss: 136.95420837402344\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 179.135009765625\n",
      "Epoch 5001, Loss: 137.49305725097656\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 178.99444580078125\n",
      "Epoch 5001, Loss: 137.50074768066406\n",
      "0.7615906833550969 0.2829017852465592\n",
      "0.5146177755767232 0.30182772022505894\n",
      "1.2667496185812026 0.3009697671710372\n",
      "-0.6280731983860307 1.8359384272050414\n",
      "0.8437925561197422 0.23590996806951176\n",
      "0.3942434936886753 0.33279929341343933\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 237.51943969726562\n",
      "Epoch 5001, Loss: 194.49130249023438\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 235.56797790527344\n",
      "Epoch 5001, Loss: 192.37057495117188\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 239.99240112304688\n",
      "Epoch 5001, Loss: 196.53590393066406\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 236.69020080566406\n",
      "Epoch 5001, Loss: 193.53811645507812\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 236.41500854492188\n",
      "Epoch 5001, Loss: 193.13650512695312\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 239.79592895507812\n",
      "Epoch 5001, Loss: 196.58250427246094\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 236.44662475585938\n",
      "Epoch 5001, Loss: 193.02655029296875\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 233.394775390625\n",
      "Epoch 5001, Loss: 190.04592895507812\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 238.10498046875\n",
      "Epoch 5001, Loss: 194.94448852539062\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 234.92623901367188\n",
      "Epoch 5001, Loss: 191.8418731689453\n",
      "0.6452377936214614 0.27818828157230263\n",
      "0.5874469051085617 0.4339382252177657\n",
      "0.9322643567611403 0.27501720046745715\n",
      "0.16886192948467965 0.5993933843457269\n",
      "0.9648630844159396 0.21531358760287975\n",
      "0.1795495707326566 0.41547480396231967\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.350830078125\n",
      "Epoch 5001, Loss: 317.0440979003906\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.42559814453125\n",
      "Epoch 5001, Loss: 317.2923278808594\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.3779296875\n",
      "Epoch 5001, Loss: 317.08929443359375\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.376708984375\n",
      "Epoch 5001, Loss: 317.24969482421875\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.4898986816406\n",
      "Epoch 5001, Loss: 317.2691650390625\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.4943542480469\n",
      "Epoch 5001, Loss: 317.3194580078125\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.9715270996094\n",
      "Epoch 5001, Loss: 317.8033142089844\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.94366455078125\n",
      "Epoch 5001, Loss: 317.73663330078125\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.9049072265625\n",
      "Epoch 5001, Loss: 317.75799560546875\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 371.95025634765625\n",
      "Epoch 5001, Loss: 317.78411865234375\n",
      "0.22774609206213303 0.021039241162809964\n",
      "0.7981702295807792 0.030428134083427143\n",
      "0.3367017761034231 0.04827064321566441\n",
      "0.599793556414131 0.1279800828222254\n",
      "0.3662569897415656 0.03440610157684081\n",
      "0.545691813738873 0.09047514508552876\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 360.8374328613281\n",
      "Epoch 5001, Loss: 306.5137939453125\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 360.6630859375\n",
      "Epoch 5001, Loss: 306.2957458496094\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 356.25311279296875\n",
      "Epoch 5001, Loss: 301.9444885253906\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 360.86492919921875\n",
      "Epoch 5001, Loss: 306.3443603515625\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 358.2475280761719\n",
      "Epoch 5001, Loss: 303.96722412109375\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 360.8650207519531\n",
      "Epoch 5001, Loss: 306.33294677734375\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 355.4834899902344\n",
      "Epoch 5001, Loss: 301.59564208984375\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 352.86370849609375\n",
      "Epoch 5001, Loss: 299.12591552734375\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 355.4791259765625\n",
      "Epoch 5001, Loss: 301.5604248046875\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 355.4813537597656\n",
      "Epoch 5001, Loss: 301.5787658691406\n",
      "1.5924827640296173 0.4961209325718813\n",
      "-3.3004575453433915 5.797224298729146\n",
      "1.2272309987872887 0.31917455821567\n",
      "-2.23992004687687 6.261979505684279\n",
      "1.10592846566083 0.4138571007608048\n",
      "-0.7411417091585578 1.789011782537375\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 1315.739501953125\n",
      "Epoch 5001, Loss: 1257.272216796875\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 967.6072998046875\n",
      "Epoch 5001, Loss: 895.1322631835938\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 1153.6849365234375\n",
      "Epoch 5001, Loss: 1086.776611328125\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 1153.5867919921875\n",
      "Epoch 5001, Loss: 1087.003662109375\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 1128.87744140625\n",
      "Epoch 5001, Loss: 1063.5064697265625\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 1153.5810546875\n",
      "Epoch 5001, Loss: 1086.7364501953125\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 969.3366088867188\n",
      "Epoch 5001, Loss: 897.0223388671875\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 944.6392822265625\n",
      "Epoch 5001, Loss: 873.6611328125\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 969.328369140625\n",
      "Epoch 5001, Loss: 897.0654296875\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "Epoch 1, Loss: 969.3378295898438\n",
      "Epoch 5001, Loss: 897.08251953125\n",
      "2.015126641678235 1.4292730220598604\n",
      "-28.34679425440212 65.48095898559235\n",
      "1.9633971182046224 0.9408330680166944\n",
      "-64.97413915915023 122.86805937930366\n",
      "1.0951364215433914 0.8090433075213921\n",
      "-22.79957958788493 66.9953470233261\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 582.1149291992188\n",
      "Epoch 5001, Loss: 528.016357421875\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 590.7354736328125\n",
      "Epoch 5001, Loss: 536.3867797851562\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 595.3162841796875\n",
      "Epoch 5001, Loss: 541.3594970703125\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 635.0988159179688\n",
      "Epoch 5001, Loss: 580.6639404296875\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 599.9658813476562\n",
      "Epoch 5001, Loss: 545.8445434570312\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 586.6458740234375\n",
      "Epoch 5001, Loss: 532.5572509765625\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 574.9522705078125\n",
      "Epoch 5001, Loss: 521.2205810546875\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 629.2230834960938\n",
      "Epoch 5001, Loss: 574.67236328125\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 609.2935791015625\n",
      "Epoch 5001, Loss: 554.9630126953125\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 581.4539794921875\n",
      "Epoch 5001, Loss: 526.3623657226562\n",
      "1.2415606053185453 0.42877372968816474\n",
      "-0.6946075550190519 0.851076599429232\n",
      "1.2895664862574445 0.4223032047784665\n",
      "-1.292299706028917 2.039897964503091\n",
      "1.3851409043225862 0.2788081993828044\n",
      "-1.5440568858704826 1.4950446572126124\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 240.99447631835938\n",
      "Epoch 5001, Loss: 187.2002410888672\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 206.0907440185547\n",
      "Epoch 5001, Loss: 153.49420166015625\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 241.55313110351562\n",
      "Epoch 5001, Loss: 187.68777465820312\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 241.8350372314453\n",
      "Epoch 5001, Loss: 187.96946716308594\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 223.5424346923828\n",
      "Epoch 5001, Loss: 170.15406799316406\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 241.82887268066406\n",
      "Epoch 5001, Loss: 187.9713897705078\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 209.7815704345703\n",
      "Epoch 5001, Loss: 157.03257751464844\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 191.48263549804688\n",
      "Epoch 5001, Loss: 139.57325744628906\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 209.7742919921875\n",
      "Epoch 5001, Loss: 157.04965209960938\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "Epoch 1, Loss: 209.77809143066406\n",
      "Epoch 5001, Loss: 157.01211547851562\n",
      "0.5157205663861391 0.3379114823214301\n",
      "-8.505238844145584 9.834366528567118\n",
      "0.974957110909871 0.3124397797246477\n",
      "-172.84170230167575 302.50598872321586\n",
      "0.9251783637838826 0.3462079382923867\n",
      "-169.1811763973713 200.90296042933264\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 657.1886596679688\n",
      "Epoch 5001, Loss: 600.01220703125\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 715.2477416992188\n",
      "Epoch 5001, Loss: 658.0552978515625\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 656.240966796875\n",
      "Epoch 5001, Loss: 599.3536376953125\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 713.8641357421875\n",
      "Epoch 5001, Loss: 656.4144287109375\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 717.67919921875\n",
      "Epoch 5001, Loss: 659.990234375\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 713.86181640625\n",
      "Epoch 5001, Loss: 656.5145263671875\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 712.1722412109375\n",
      "Epoch 5001, Loss: 655.1358032226562\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 715.9896240234375\n",
      "Epoch 5001, Loss: 658.5543823242188\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 712.1715087890625\n",
      "Epoch 5001, Loss: 655.0025634765625\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "Epoch 1, Loss: 712.1693725585938\n",
      "Epoch 5001, Loss: 655.0232543945312\n",
      "3.517859871960897 1.3465188382643711\n",
      "-1012.9285082459049 1482.653393107819\n",
      "3.94022447845272 0.9647391010835238\n",
      "-938.9526198379639 1422.6012176830313\n",
      "3.0833492674522773 1.5317510442766133\n",
      "-1012.9379974149155 1482.6694542648193\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maeo = []\n",
    "    list_r2o = []\n",
    "    list_maep = []\n",
    "    list_r2p = []\n",
    "    list_maei = []\n",
    "    list_r2i = []\n",
    "    \n",
    "    for tno in range(10):\n",
    "\n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation original\n",
    "        model_original = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_original.fit(X_train, y_train)\n",
    "        y_pred_original = model_original.predict(X_test)\n",
    "        mae_original = mean_absolute_error(y_test, y_pred_original)\n",
    "        r2score_original = r2_score(y_test, y_pred_original)    \n",
    "\n",
    "        ## evaluation pca\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        train_data = TensorDataset(X_train_tensor, X_train_tensor)  # Input is the same as target\n",
    "        train_loader = DataLoader(train_data, batch_size=10000, shuffle=True)\n",
    "        autoencoder = Autoencoder(len_emb=1024, abs_len_emb=256)\n",
    "        optimizer = optim.Adam(autoencoder.parameters(), lr=1e-4)\n",
    "        criterion = nn.L1Loss(reduction='mean')\n",
    "        epochs = 10000\n",
    "        for epoch in range(epochs):\n",
    "            for data, target in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                pred = autoencoder(data)\n",
    "                loss = criterion(pred, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch%5000==0:\n",
    "                print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "        # Use the encoder to transform the training and test data\n",
    "        with torch.no_grad():\n",
    "            X_train_pca = autoencoder.encoder(X_train_tensor)\n",
    "            X_test_pca = autoencoder.encoder(X_test_tensor)\n",
    "        X_train_pca = X_train_pca.numpy()\n",
    "        X_test_pca = X_test_pca.numpy()\n",
    "        model_pca = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_pca.fit(X_train_pca, y_train)\n",
    "        y_pred_pca = model_pca.predict(X_test_pca)\n",
    "        mae_pca = mean_absolute_error(y_test, y_pred_pca)\n",
    "        r2score_pca = r2_score(y_test, y_pred_pca)    \n",
    "\n",
    "        ## evaluation invariant\n",
    "        len_embedding = 1024\n",
    "        abstract_len_embedding = int(len_embedding*0.25)\n",
    "        model_path = curdir + 'v2_script_10/exp12/model_invariant_' + exp_name + '.pt'\n",
    "        model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant.eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maeo.append(mae_original)\n",
    "        list_r2o.append(r2score_original)\n",
    "        list_maep.append(mae_pca)\n",
    "        list_r2p.append(r2score_pca)\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maeo), np.std(list_maeo))\n",
    "    print(np.mean(list_r2o), np.std(list_r2o))\n",
    "    print(np.mean(list_maep), np.std(list_maep))\n",
    "    print(np.mean(list_r2p), np.std(list_r2p))\n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4553087-b303-47fd-a93b-9b5ceefec61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## try old models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8e4bdae-4e36-4b9b-b5d6-fd9665264098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction='mean')\n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*1)),\n",
    "\n",
    "            nn.Linear(int(self.len_embedding*1), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "\n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*1)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp_11b.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e416f21-ef46-4702-a3dc-8b39618ecdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.1479986335967676 0.1984122481376579\n",
      "-0.17681220230381037 1.4532845177471967\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "1.2377920212488231 0.1806609158878257\n",
      "-0.3499429610888127 0.5070091171104871\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "1.0132347422327497 0.23358037628879538\n",
      "0.11468828624780211 0.7897280232579731\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "0.854590090271355 0.4177241296482591\n",
      "0.15400270058431334 0.7696267685078214\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.25222428658609414 0.025577827065960002\n",
      "0.7591079895348846 0.06145068859235018\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "1.5400171254910646 0.5313078964492223\n",
      "-4.226018187253993 9.354742149707667\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "1.6727275622677298 1.1813905559600864\n",
      "-20.579688557030675 37.62332771097068\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.629804328746839 0.3119398046559622\n",
      "-2.011244428017167 1.042197691250326\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.883626945181416 0.3374320890231954\n",
      "-152.22002716404208 204.83210365248254\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "3.2414801337414163 1.9345154346355167\n",
      "-1248.758618346521 1821.7871045525317\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "    \n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant.eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05193f92-7841-4412-a123-5aa3198213ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction='mean')\n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*1)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*1)),\n",
    "\n",
    "            nn.Linear(int(self.len_embedding*1), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)\n",
    "\n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*1)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp_11c.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d78ac0a-0ecb-428b-b873-58c53437da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.5371081900728427 0.3977396771224058\n",
      "-0.6752682870040198 0.7587750199690733\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "1.3804927404112015 0.18119887631441509\n",
      "-0.5271884091112679 0.3932237110464372\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "0.9459476894587221 0.3386844193383047\n",
      "0.2548853312411832 0.6345026866564444\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "0.7531258650530117 0.29588493718273273\n",
      "0.5310819502542254 0.3245124880380526\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.400107203634382 0.04155633596682076\n",
      "0.40257766457971966 0.07606776281958239\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "1.2510882855113465 0.25305323657481776\n",
      "-2.7815344240723685 7.077694419822349\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "1.373771528891686 0.9460343493311604\n",
      "-16.65833051724882 38.73418971209187\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.4844448253015643 0.29319521849307156\n",
      "-1.6411848752007874 0.8933543814590443\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.5309803232727675 0.31929352166735614\n",
      "-14.631632442063813 21.2517277160128\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "3.427577348476538 1.5696621488555584\n",
      "-1237.4246953235702 1826.2531101273855\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "    \n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant.eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce0e1746-0ca2-495b-9c4a-8e209ca3c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss() \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.encoder = nn.Sequential(\n",
    "            ## 1024 to ...\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.5)), \n",
    "            ## ... to ...\n",
    "            nn.Linear(int(self.len_embedding*0.5), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding, int(self.abstract_len_embedding * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.abstract_len_embedding * 0.5)),  # Add BatchNorm1d here\n",
    "            nn.Linear(int(self.abstract_len_embedding * 0.5), 1)\n",
    "        )\n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding, int(self.abstract_len_embedding * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.abstract_len_embedding * 0.5)),  # Add BatchNorm1d here\n",
    "            nn.Linear(int(self.abstract_len_embedding * 0.5), 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp9i.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1201385a-5668-4c3f-aa49-1b078f907da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.0479749359530188 0.1720054696549971\n",
      "0.1941782828909441 0.5519110913594564\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "0.9403687554122142 0.14420230562130643\n",
      "0.2515258722885817 0.233477801737872\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "0.888292544428554 0.20994347377827186\n",
      "0.3299781233796163 0.425559578026022\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "1.1549093908819354 0.3553573157163484\n",
      "-0.20824821122830847 1.004880279909111\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.41227834797266033 0.023948402163088474\n",
      "0.3611917303279478 0.14862508709735134\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "1.4822421698898125 0.4555891927995676\n",
      "-4.449690701074433 9.139848974822582\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "1.1739786201807036 0.814358956853253\n",
      "-23.378596349194428 66.73976573662239\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.4792542404685676 0.242175333619779\n",
      "-2.0006087593916613 1.0764413518003055\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.9251736723126527 0.3338630470195867\n",
      "-169.2694554779269 200.88452368565947\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "3.5625177419909138 1.3709060822057002\n",
      "-1133.1369507076492 1647.54477874537\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "    \n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant.eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b531fa8-600e-4fd5-acba-196d74d1e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.encoder = nn.Sequential(\n",
    "            ## 1024 to ...\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.5)), \n",
    "            ## ... to ...\n",
    "            nn.Linear(int(self.len_embedding*0.5), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding, int(self.abstract_len_embedding * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.abstract_len_embedding * 0.5)),  # Add BatchNorm1d here\n",
    "            nn.Linear(int(self.abstract_len_embedding * 0.5), 1)\n",
    "        )\n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding, int(self.abstract_len_embedding * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.abstract_len_embedding * 0.5)),  # Add BatchNorm1d here\n",
    "            nn.Linear(int(self.abstract_len_embedding * 0.5), 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp9h.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cea2d9b4-0428-4aaf-8fe7-f492a3b3b0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.2507344166754328 0.28763506410644457\n",
      "-0.011201906495235748 0.41778440056457933\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "0.8666693413998982 0.22528857236164188\n",
      "0.3514259845698113 0.3395357695778172\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "0.8907852777699974 0.2881615069352623\n",
      "0.057058276461246546 1.6299611396067157\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "0.983042004819777 0.26165533342143577\n",
      "0.27166710148319095 0.3669711310591682\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.3014892356873847 0.04726524017987658\n",
      "0.6816270043845133 0.0876326091080832\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "2.002940986762789 0.8018141140012648\n",
      "-4.4077089228896735 7.578773018759796\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "1.5808013793858862 1.2274543780011273\n",
      "-16.9773899573768 43.20980824917635\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.239908405954981 0.2888590045540196\n",
      "-1.3644383550761916 2.1830255633009057\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.5458352944328325 0.33062721405543277\n",
      "-9.0190089625742 9.998666815530243\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "2.4431002776943496 1.4456643449309157\n",
      "-690.7789172333819 988.7184665246931\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "\n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        # model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant = DataParallel(InvariantModel(len_embedding, abstract_len_embedding))    \n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant = model_invariant.module    \n",
    "        model_invariant.train() ## eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a2bef8e-3a1c-4c2f-975e-2581c11660c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.encoder = nn.Sequential(\n",
    "            ## 1024 to ...\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.5)), \n",
    "            ## ... to ...\n",
    "            nn.Linear(int(self.len_embedding*0.5), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding, int(self.abstract_len_embedding * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.abstract_len_embedding * 0.5)),  # Add BatchNorm1d here\n",
    "            nn.Linear(int(self.abstract_len_embedding * 0.5), 1)\n",
    "        )\n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding, int(self.abstract_len_embedding * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.abstract_len_embedding * 0.5)),  # Add BatchNorm1d here\n",
    "            nn.Linear(int(self.abstract_len_embedding * 0.5), 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp9f.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bb5ff57-41ab-4a0a-a2b7-c62f0d9069c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.1215503688190902 0.20789104176487688\n",
      "-0.16236661220683218 1.0452307280527935\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "0.8012602308894854 0.12009600704051107\n",
      "0.43934184448049346 0.18163973798470817\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "0.8748166867976833 0.18726846656497695\n",
      "0.25827783818032785 0.7912511234430982\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "0.8318066336999024 0.17658398385335158\n",
      "0.30892306347017034 0.4867510234613535\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.28410885884106607 0.04343935079695209\n",
      "0.7330511921278299 0.07216917349603985\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "1.2952202694415547 0.32623058968452034\n",
      "-2.1999410713145267 4.020933788236961\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "2.0557414076851885 0.8492722439603906\n",
      "-57.0043496910629 119.05251542910342\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.4074971407119632 0.2643389119444069\n",
      "-1.7744893183424622 2.4274978331398844\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.9593566354505014 0.0451311460853954\n",
      "-158.44157744160174 198.25247665084592\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "3.7684560221918155 1.4651364378245038\n",
      "-1130.3308748188415 1655.8112517584998\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "\n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        # model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant = DataParallel(InvariantModel(len_embedding, abstract_len_embedding))    \n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant = model_invariant.module    \n",
    "        model_invariant.train() ## eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a9a9012-184c-49c5-a181-64999599f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.encoder = nn.Sequential(\n",
    "            ## 1024 to ...\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.5)), \n",
    "            ## ... to ...\n",
    "            nn.Linear(int(self.len_embedding*0.5), self.abstract_len_embedding),\n",
    "        )\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding, int(self.abstract_len_embedding * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.abstract_len_embedding * 0.5)),  # Add BatchNorm1d here\n",
    "            nn.Linear(int(self.abstract_len_embedding * 0.5), 1)\n",
    "        )\n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.Linear(self.abstract_len_embedding, int(self.abstract_len_embedding * 0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.abstract_len_embedding * 0.5)),  # Add BatchNorm1d here\n",
    "            nn.Linear(int(self.abstract_len_embedding * 0.5), 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp9g.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b5b9e3b2-ccdb-4ec5-b453-629269717821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.2507344166754328 0.28763506410644457\n",
      "-0.011201906495235748 0.41778440056457933\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "0.8666693413998982 0.22528857236164188\n",
      "0.3514259845698113 0.3395357695778172\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "0.8907852777699974 0.2881615069352623\n",
      "0.057058276461246546 1.6299611396067157\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "0.983042004819777 0.26165533342143577\n",
      "0.27166710148319095 0.3669711310591682\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.3014892356873847 0.04726524017987658\n",
      "0.6816270043845133 0.0876326091080832\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "2.002940986762789 0.8018141140012648\n",
      "-4.4077089228896735 7.578773018759796\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "1.5808013793858862 1.2274543780011273\n",
      "-16.9773899573768 43.20980824917635\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.239908405954981 0.2888590045540196\n",
      "-1.3644383550761916 2.1830255633009057\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.5458352944328325 0.33062721405543277\n",
      "-9.0190089625742 9.998666815530243\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "2.4431002776943496 1.4456643449309157\n",
      "-690.7789172333819 988.7184665246931\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "\n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        # model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant = DataParallel(InvariantModel(len_embedding, abstract_len_embedding))    \n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant = model_invariant.module    \n",
    "        model_invariant.train() ## eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "080f05b4-c4b1-45d3-adcf-a586852cb933",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.encoder = nn.Sequential(\n",
    "            ## 1024 to ...\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.5)), \n",
    "            ## ... to ...\n",
    "            nn.Linear(int(self.len_embedding*0.5), self.abstract_len_embedding),\n",
    "        )        \n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)  # For dataset 1\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)  # For dataset 2\n",
    "\n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.25)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp9e.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c476ad0a-215c-4821-a657-3dc63aab7def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.3979544583288552 0.25000718858710347\n",
      "-0.8057880291617348 2.2263920427489765\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "0.8916190556944112 0.11354088305310112\n",
      "0.34470178060253415 0.20632362790238948\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "0.8989331431408875 0.19806927783331388\n",
      "0.14667911704100808 1.1630074807720694\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "1.0245938432785597 0.3207461592644017\n",
      "0.21817061957310552 0.3943481368216906\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.401334771400751 0.045275617056493855\n",
      "0.4652369304027898 0.136735386535141\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "1.7511522258832628 0.5346460249317896\n",
      "-3.6894479060249568 6.038951470499066\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "1.6685207997756053 0.6927292021165614\n",
      "-28.776360806340914 38.22169802306751\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.278070780946464 0.31145924422072374\n",
      "-1.5962905462552583 2.3428018397628234\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "1.1309551611719755 0.3997667719020248\n",
      "-308.1547961881801 428.2673071133137\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "2.8949087836437597 0.7590717887077079\n",
      "-554.2072341957563 775.7493777951535\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "\n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        # model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant = DataParallel(InvariantModel(len_embedding, abstract_len_embedding))    \n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant = model_invariant.module    \n",
    "        model_invariant.train() ## eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "992532aa-85a7-43d0-9526-281dfcf06e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.encoder = nn.Sequential(\n",
    "            ## 1024 to ...\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding)), \n",
    "            ## ... to ...\n",
    "            nn.Linear(int(self.len_embedding), self.abstract_len_embedding),\n",
    "        )        \n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)  # For dataset 1\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)  # For dataset 2\n",
    "\n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*1)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp9d.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87613db9-cee6-424d-8ed3-a5f40be45400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.2939100129265326 0.19227543417680212\n",
      "-0.2160203721183413 0.8214441907775833\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "0.8544712696822276 0.1438566538839704\n",
      "0.39008619658108334 0.18622620893829261\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "1.0015584523750718 0.18396053198423756\n",
      "0.11983285165025108 0.8452188733218087\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "0.9487965715321177 0.22023196421627336\n",
      "0.2359578030616273 0.548099167299369\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.31802102615115757 0.0495087321906324\n",
      "0.6676942631229033 0.11568082252985719\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "1.4274876073520972 0.51204861295226\n",
      "-3.5509375570431616 6.020720895352783\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "2.5088452938546792 0.5501178224096762\n",
      "-109.29413581994717 157.58208131839643\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.4412913867743418 0.17775113976748935\n",
      "-1.4901130254051167 1.2334360818101173\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.5396785293552255 0.3397779005676339\n",
      "-7.169403717798059 7.712077325485507\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "2.715106489187369 1.081208705582878\n",
      "-550.3477385179424 778.4286273332883\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "\n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        # model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant = DataParallel(InvariantModel(len_embedding, abstract_len_embedding))    \n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant = model_invariant.module    \n",
    "        model_invariant.train() ## eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "852fb010-3b7b-4e9d-8553-dea93bd9b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.encoder = nn.Sequential(\n",
    "            ## 1024 to ...\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*2)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*2)), \n",
    "            ## ... to ...\n",
    "            nn.Linear(int(self.len_embedding*2), int(self.len_embedding*1.5)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*1.5)),\n",
    "            ## ... to ...\n",
    "            nn.Linear(int(self.len_embedding*1.5), self.abstract_len_embedding),\n",
    "        )        \n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)  # For dataset 1\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)  # For dataset 2\n",
    "\n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*1)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp9c.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86a9320b-fe12-4ecd-96b7-43133d6089cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.2751408608681305 0.25528533357267547\n",
      "-0.22496852022930636 0.9191321874133979\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "1.1242252822186396 0.1441779288325659\n",
      "0.08069301049006948 0.2525568698826667\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "1.1701268617408385 0.28166513995296943\n",
      "-0.21123347693394873 1.0239006500636663\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "1.1734560421861662 0.2720112357708375\n",
      "0.04101041431715371 0.5680583756882532\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.4836324159309586 0.06461282907830741\n",
      "0.27531772734439286 0.1704256774564355\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "1.7164407342250712 0.4303918380363266\n",
      "-5.790704935084017 10.909544114563271\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "2.548765757756546 0.5801488228152958\n",
      "-93.84830333520105 110.2162390757472\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.3322194026102214 0.24102253590945474\n",
      "-1.1901279781149314 1.1966644463154363\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.7968361719089018 0.3047873965936618\n",
      "-161.2190501940441 236.40023363860504\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "2.5288272962956597 1.481636075553814\n",
      "-576.8690957859915 797.0446125030161\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "\n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        # model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant = DataParallel(InvariantModel(len_embedding, abstract_len_embedding))    \n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant = model_invariant.module    \n",
    "        model_invariant.train() ## eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10ebc059-9984-4ef0-b728-2efd4a70a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## class\n",
    "class InvariantModel(nn.Module):\n",
    "    def __init__(self, len_embedding, abstract_len_embedding):\n",
    "        super(InvariantModel, self).__init__()\n",
    "        self.loss = nn.L1Loss(reduction=\"mean\") \n",
    "        self.len_embedding = len_embedding\n",
    "        self.abstract_len_embedding = abstract_len_embedding  \n",
    "        self.encoder = nn.Sequential(\n",
    "            ## 1024 to 2048\n",
    "            nn.Linear(self.len_embedding, int(self.len_embedding*0.875)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.875)), \n",
    "            ## 2048 to 1536\n",
    "            nn.Linear(int(self.len_embedding*0.875), int(self.len_embedding*0.75)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(int(self.len_embedding*0.75)),\n",
    "            ## 1536 to 1024\n",
    "            nn.Linear(int(self.len_embedding*0.75), self.abstract_len_embedding),\n",
    "        )        \n",
    "        self.head1 = nn.Linear(self.abstract_len_embedding, 1)  # For dataset 1\n",
    "        self.head2 = nn.Linear(self.abstract_len_embedding, 1)  # For dataset 2\n",
    "\n",
    "    def forward(self, x, dataset_id):\n",
    "        x = self.encoder(x)\n",
    "        if dataset_id == 1:\n",
    "            return self.head1(x)\n",
    "        else:\n",
    "            return self.head2(x)\n",
    "        \n",
    "len_embedding = 1024\n",
    "abstract_len_embedding = int(len_embedding*0.5)\n",
    "model_path = curdir + 'v2_script_10/model_invariant_exp9.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "07454213-48ca-43a4-9d6a-4cf266d1a68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "pid: AraComputational2022, df.shape:(64, 1025), dft_func: PBE-D3\n",
      "1.3706716817751428 0.22315154980921315\n",
      "-0.20644334093934275 0.7311316288749727\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "pid: BajdichWO32018, df.shape:(84, 1025), dft_func: PBE+U\n",
      "1.1499627605874128 0.13571273820367966\n",
      "0.017013405736821585 0.21175320421032454\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "pid: BoesAdsorption2018, df.shape:(49, 1025), dft_func: RPBE\n",
      "1.0973794266720305 0.2881033792557032\n",
      "-0.3385772606473605 1.5222807636776603\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "pid: ComerUnraveling2022, df.shape:(66, 1025), dft_func: PBE+U\n",
      "1.4162149939016149 0.33073482123921305\n",
      "-0.26365049723773615 0.4969985935218852\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "pid: HossainInvestigation2022, df.shape:(365, 1025), dft_func: PBE+U\n",
      "0.4856416156852418 0.08003441730803895\n",
      "0.25142943488697556 0.20120436171581943\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: KoshyInvestigation2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "1.6520301938904793 0.4355458769659558\n",
      "-3.941512279851588 7.729619470918973\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "pid: LiuCatalytic2022, df.shape:(6, 1025), dft_func: RPBE\n",
      "1.4417189390233303 0.4870216426864224\n",
      "-21.857476455497824 25.781111798148622\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "pid: RaoResolving2022, df.shape:(26, 1025), dft_func: PBE+U\n",
      "1.408477476848084 0.32645218620297933\n",
      "-1.306983223255725 1.6160491502511205\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "pid: TettehCompressively2022, df.shape:(6, 1025), dft_func: PBE\n",
      "0.6494344826928569 0.31736168107246554\n",
      "-19.50074531553912 31.879193223873855\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "pid: WeiInsights2022, df.shape:(6, 1025), dft_func: PBE+U\n",
      "2.8766319796069553 1.5087561568195393\n",
      "-554.0610586631398 776.2767033523733\n"
     ]
    }
   ],
   "source": [
    "for pid in list_pid[:]:\n",
    "    list_maei = []\n",
    "    list_r2i = []    \n",
    "    for tno in range(10):\n",
    "\n",
    "        with open(f'{curdir}v2_script_10/exp12/df_{pid}.pickle', 'rb') as f:\n",
    "            df = pickle.load(f)  \n",
    "        with open(f'{curdir}v2_script_10/exp12/dict_{pid}.pickle', 'rb') as f:\n",
    "            dinfo = pickle.load(f)          \n",
    "        ##\n",
    "        if int(df.shape[0]) < 0:\n",
    "            continue\n",
    "        ##\n",
    "        print(f'pid: {pid}, df.shape:{df.shape}, dft_func: {dinfo[0][\"dft_func\"]}')    \n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df['nre'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio_test, random_state=seed+tno)\n",
    "\n",
    "        ## evaluation invariant\n",
    "        # model_invariant = InvariantModel(len_embedding, abstract_len_embedding)\n",
    "        model_invariant = DataParallel(InvariantModel(len_embedding, abstract_len_embedding))    \n",
    "        model_invariant.load_state_dict(torch.load(model_path))\n",
    "        model_invariant = model_invariant.module    \n",
    "        model_invariant.train() ## eval()\n",
    "        X_train_invariant = model_invariant.encoder(torch.tensor(X_train, dtype=torch.float32)).detach().numpy()\n",
    "        X_test_invariant = model_invariant.encoder(torch.tensor(X_test, dtype=torch.float32)).detach().numpy()\n",
    "        model_invariant = xgb.XGBRegressor(learning_rate=0.2, max_depth=8, n_estimators=500)\n",
    "        model_invariant.fit(X_train_invariant, y_train)\n",
    "        y_pred_invariant = model_invariant.predict(X_test_invariant)\n",
    "        mae_invariant = mean_absolute_error(y_test, y_pred_invariant)\n",
    "        r2score_invariant = r2_score(y_test, y_pred_invariant)\n",
    "\n",
    "        list_maei.append(mae_invariant)\n",
    "        list_r2i.append(r2score_invariant)\n",
    "        \n",
    "    print(np.mean(list_maei), np.std(list_maei))\n",
    "    print(np.mean(list_r2i), np.std(list_r2i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a2eae6-db47-448a-a4d9-5e11b8e10af6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af67b7-8958-4e3b-bab8-a6cb3c194e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8acf5c-aa9e-4e00-9a6e-efe84c16d99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aac31a-7236-4302-9bcb-0e228863252e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1acebf-908b-47f2-a428-4db479ef78ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
